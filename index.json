[{"content":" Ansible Practices and help # This file should provide you with help on how to use my Ansible init scripts. Also I will provide you with info on my best practices, knowhows and nice to have stuff. On your automation journey.\nAnsible Repository Initialization Guide # This guide provides detailed instructions on how to use the initialize_ansible_repo.sh script to set up a new Ansible repository with a predefined directory structure and configuration. It also includes guidelines for developing within the playbook.\nAbout the Script # The initialize_ansible_repo.sh script is designed to streamline the setup of a new Ansible repository. It automatically creates a set of directories and files that are commonly used in Ansible projects, including roles, inventories, collections, and variable directories. Additionally, the script generates an Ansible configuration file and a vault password file with a random password.\nRepository Structure # Upon execution, the script creates the following directory structure in the specified repository path:\nroles/: Directory for Ansible roles. inventories/: Directory for inventory files. collections/: Directory for Ansible collections. vars/: Directory for variable files. scripts/: Directory for storing scripts, including the initialization scripts. The script also creates several configuration files:\nansible.cfg: An Ansible configuration file with predefined settings. requirements.yml files in both the roles and collections directories for managing dependencies. .gitignore: Configured to exclude specific directories from version control while keeping their requirements files. Vault password file: Located in ~/.vault_keys/, used for Ansible Vault operations. How to Use the Script # To set up your new Ansible repository using the initialize_ansible_repo.sh script, follow these steps:\nDownload the Script\nDownload the script from the official repository using this command:\nwget https://raw.githubusercontent.com/Ebdruplab/ansible-shared/main/scripts/initialize_ansible_repo.sh Make the Script Executable\nChange the permissions of the script to make it executable with the following command:\nchmod +x initialize_ansible_repo.sh Execute the Script\nRun the script by specifying the directory where you want to initialize your new Ansible repository:\n./initialize_ansible_repo.sh ~/path/to/your/new/ansible-repo This will create the necessary directory structure, configuration files, and initialization scripts as described in the earlier sections.\nDevelopment Practices # You can on your development bench use the init_dev.sh, this will export the vault password file. NOTE: you offcourse need to add a value to this file to use it. Standard location from script is: ~/.vault_keys/repo-name I would recommend using a minimum of 32 charactes for the vault password as it isn\u0026rsquo;t really something you want to be cracked.\nAnsible Collections # This will guide you in creating collections. I will provide you with info from my own expirence. This means that what I provide you with is mainly something used to create a collection for a firm. I will be calling the firm in my guide ebdruplab, but it could be what ever company. I will also provide you with information on how those created collections can be pushed to Private Automationhub. I will also make a snippet on how you can push code to here with a API key.\nI would suggets creating a github or what ever git software you use. e.g ansible_collection_ebdruplab. If it should be available at ansible galaxy. You would need to make it public.\nTHe collection I have and will keep on developing on is at ansible_collection_ebdruplab\nCollection Creation # Here I provide you with info on how you could generate your own ansible collection. A collection consist of 3 things:\ne.g ebdruplab \u0026lt;collection_name\u0026gt; e.g linux, windows or something else \u0026lt;role_name\u0026gt; wihin each namespace.collection_name you can generate a role ansible-galaxy role init podman_stack ansible-galaxy collection init ebdruplab.linux cd ebdruplab/linux/roles ansible-galaxy role init podman_stack # You can then provide info for the role and for the collection in the diffrent readme files. vi README.md # To build the collection use ansible-galaxy collection build # This should be done in the dir with the build .yml file Bash Scripts # To make it a bit easier to push collection to private automation hub you can use the following bash scripts. Thease are for publishing collection, and if you want to install from your own automation platform.\n# Functions for managing collections in a Private Automation Hub # Publish a collection to the Automation Hub publish_collection() { if [[ -z \u0026#34;$1\u0026#34; ]]; then echo \u0026#34;Error: Missing argument.\u0026#34; echo \u0026#34;Usage: publish_collection \u0026lt;collection_archive\u0026gt;\u0026#34; return 1 # Return with error fi ansible-galaxy collection publish \u0026#34;$1\u0026#34; --api-key=\u0026#34;$AUTOMATIONHUB_API_KEY\u0026#34; -s \u0026#34;$AUTOMATIONHUB_SERVER\u0026#34; echo \u0026#34;Collection published successfully.\u0026#34; } # Install a collection from the Automation Hub install_collection() { if [[ -z \u0026#34;$1\u0026#34; ]]; then echo \u0026#34;Error: Missing argument.\u0026#34; echo \u0026#34;Usage: install_collection namespace/collection_name [options]\u0026#34; return 1 # Return with error fi ansible-galaxy collection install \u0026#34;$1\u0026#34; --api-key=\u0026#34;$AUTOMATIONHUB_API_KEY\u0026#34; -s \u0026#34;$AUTOMATIONHUB_SERVER\u0026#34; echo \u0026#34;Collection installed successfully.\u0026#34; } And for the export list:\n# Export for ansible scripts export AUTOMATIONHUB_API_KEY=\u0026lt;API_KEY\u0026gt; export AUTOMATIONHUB_SERVER=https://\u0026lt;Automation_Hub\u0026gt; I will not explain how to load these on login. But it include using your .bash_profile, and for my own example I use the .config with some .bash_private and .bash_public files.\n","date":"14 April 2024","externalUrl":null,"permalink":"/posts/01-ansible/ansible-best-practices/ansible/","section":"IT Projects and Resources","summary":"Ansible Practices and help # This file should provide you with help on how to use my Ansible init scripts.","title":"Ansible Best Practices and help","type":"posts"},{"content":" Ansible Jinja2 Helpers # This post delves into the functionalities of Jinja2 templating, primarily for use with Ansible but also applicable in any language that supports Jinja2, like Python.\nWell Known Jinja2 Clauses # Easy to find and commonly used clauses:\n# Omits the variable if it does not exist, useful to prevent errors or undefined messages. {{ Ifnovariableexistremoveme | default(omit) }} # Sets the variable to \u0026#39;null\u0026#39; if it does not exist, can be used to ensure output consistency. {{ Ifnovariableexistwritenull | default(\u0026#39;null\u0026#39;) }} # Defaults to another variable if the initial variable is undefined. {{ Ifidontexistwriteanothervariable | default(othervar) }} Template .j2 file # Set a var in a jinja template based on host fact: mysql_max_connections: \u0026#34;{{ (ansible_memtotal_mb // 12) | int }}\u0026#34; A If something is true clause, or just check for defined {% if mysql_slow_query_log_enabled %} slow_query_log = 1 slow_query_log_file = {{ mysql_slow_query_log_file }} long_query_time = {{ mysql_slow_query_time }} {% endif %} # or if check it is there or not # Ansible Jinja2 if variable is defined ( where variable is defined) {% if example_variable is defined -%} example_variable is defined {% else -%} example_variable is not defined {% endif %} Jinja2 filters # Ansible Jinja2 for filters # min value {{ [1,2,3,4,5] | min }} # max value {{ [1,2,3,4,5] | max }} # unique [1, 1, 2, 2, 3, 3, 4, 4, 5, 5] {{ [1, 1, 2, 2, 3, 3, 4, 4, 5, 5] | unique }} # difference [1, 2, 3, 4, 5] vs [2, 3, 4, 5] {{ [1, 2, 3, 4, 5] | difference([2, 3, 4]) }} # random[\u0026#39;rob\u0026#39;, \u0026#39;jane\u0026#39;, \u0026#39;freddy\u0026#39;] {{ [\u0026#39;rob\u0026#39;, \u0026#39;jane\u0026#39;, \u0026#39;freddy\u0026#39;] | random }} A template.j2 with a lot of diffrent options # Jinja2 template if statement {% if ansible_hostname == \u0026#34;examplehost2\u0026#34; -%} This is {{ ansible_hostname }} host {% endif %} # Ansible Jinja2 if elif statement {% if ansible_hostname == \u0026#34;examplehost2\u0026#34; -%} This is {{ ansible_hostname }} host {% elif ansible_hostname == \u0026#34;examplehost3\u0026#34; -%} This is {{ ansible_hostname }} host with modifications {% endif %} # Ansible Jinja2 if elif else statement {% if ansible_hostname == \u0026#34;examplehost2\u0026#34; -%} This is {{ ansible_hostname }} host {% elif ansible_hostname == \u0026#34;examplehost3\u0026#34; -%} This is {{ ansible_hostname }} host with modifications {% else -%} This is default {{ ansible_hostname }} host {% endif %} # Ansible Jinja2 if variable is defined ( where variable is not defined) {% if example_variable is defined -%} example_variable is defined {% else -%} example_variable is not defined {% endif %} # Ansible Jinja2 if variable is defined ( where variable is defined) {% set example_variable = \u0026#39;defined\u0026#39; -%} {% if example_variable is defined -%} example_variable is defined {% else -%} example_variable is not defined {% endif %} # Ansible Jinja2 for loop {% for entry in ansible_all_ipv4_addresses -%} IP Address entry {{ loop.index }} - {{ entry }} {% endfor %} # Ansible Jinja2 for range {% for entry in range(1, 11) -%} {{ entry }} {% endfor %} # Ansible Jinja2 for range , reversed(simulate while greater 5) {% for entry in range(10, 0, -1) -%} {% if entry == 5 -%} {% break %} {% endif -%} {{ entry }} {% endfor %} # Ansible Jinja2 for range , reversed(continue if odd) {% for entry in range(10, 0, -1) -%} {% if entry is odd -%} {% continue %} {% endif -%} {{ entry }} {% endfor %} Lesser Known Features # More obscure yet highly useful features for complex data handling:\n# Example variable structure with nested values somenestedvar: var1: - value1 - value2 var2: - value2 - value3 # Debug task to output a unique list of all values in \u0026#39;somenestedvar\u0026#39; debug: msg: \u0026#34;{{ somenestedvar.values() | flatten | unique }}\u0026#34; This configuration shows how to extract and manipulate lists from nested data structures in Ansible using Jinja2, providing a powerful way to handle dynamic data.\n","date":"10 April 2024","externalUrl":null,"permalink":"/posts/01-ansible/ansible-jinja2/ansible/","section":"IT Projects and Resources","summary":"Ansible Jinja2 Helpers # This post delves into the functionalities of Jinja2 templating, primarily for use with Ansible but also applicable in any language that supports Jinja2, like Python.","title":"Ansible Jinja Helpers","type":"posts"},{"content":" Certificates guide # This provides info on how to generate certificates, and how to convert to diffrent certs form.\nCreating of a cert openssl.conf # Create an openssl.conf configuration, and insert: # Define all variables at the beginning for easy adjustments # openssl req -new -config openssl.conf -keyout ebdruplab_dk.key -out ebdruplab_dk.csr FQDN = ebdruplab.dk ORGNAME = ebdruplab EMAIL = example@ebdruplab.dk COUNTRY = DK STATE = 8200 CITY = Aarhus ORG_UNIT = team ALTNAMES = DNS:$FQDN, DNS:www.ebdruplab.dk [ req ] default_bits = 2048 # RSA Key size default_md = sha256 # Hashing algorithm prompt = no # Disable prompt for overriding values encrypt_key = no # Private key is not encrypted distinguished_name = dn req_extensions = req_ext # Include extensions from below [ dn ] C = $COUNTRY # Country Code ST = $STATE # State or Province L = $CITY # City O = $ORGNAME # Organization Name OU = $ORG_UNIT # Organizational Unit CN = $FQDN # Common Name for the certificate emailAddress = $EMAIL # Email Address [ req_ext ] subjectAltName = $ALTNAMES # Defines alternate names for the certificate Change the varaibles to fit your domain (remember mail, ALTNAMES and so on) Run command: openssl req -new -config openssl.conf -keyout ebdruplab_dk.key -out ebdruplab_dk.csr (change names of the keyout and -out accordenly) Encrypt the private key using command: openssl rsa -in ebdruplab_dk.key -aes256 -out encrypted_ebdruplab_dk.key (save the password in a secure vault) To decrypt the key: openssl rsa -in encrypted_ebdruplab_dk.key -out decrypted_ebdruplab_dk.key Conversion of certs # CRT to PEM: cat certificate.crt ca_bundle.crt \u0026gt; combined.pem (check that there are all on seperate lines)\nCRT to PKCS12: openssl pkcs12 -export -out ebdruplab_dk.p12 -inkey sdecrypted_ebdruplab_dk.key -in ebdruplab_dk.crt -certfile ca_bundle.crt\n","date":"15 April 2024","externalUrl":null,"permalink":"/posts/02-linux/certs/certs/","section":"IT Projects and Resources","summary":"Certificates guide # This provides info on how to generate certificates, and how to convert to diffrent certs form.","title":"Certificate Creation guide","type":"posts"},{"content":" dot files for linux # In this guide I will provide you with info on how i setup my .config and .bash_profile. I use it on a ubuntu, installed using wsl2.\nSetup # I use the following locations:\n.config/{.bash_public, .bash_private} .bash_profile, that loads my .bash_private, .bash_public and the standard items like .bashrc The newest files are located at dotfiles\nImportant Remember to change mod to 0700 and to set the owner to $USER.\nThe .bash_profile script is here, but for the newest go to the link:\n# File: .bash_profile #~/.bash_profile # System loads # ------------- # if running bash # Source .bashrc and .profile if they exist [ -f \u0026#34;$HOME/.bashrc\u0026#34; ] \u0026amp;\u0026amp; . \u0026#34;$HOME/.bashrc\u0026#34; [ -f \u0026#34;$HOME/.profile\u0026#34; ] \u0026amp;\u0026amp; . \u0026#34;$HOME/.profile\u0026#34; [ -f \u0026#34;$HOME/.config/.bash_public\u0026#34; ] \u0026amp;\u0026amp; . \u0026#34;$HOME/.config/.bash_public\u0026#34; [ -f \u0026#34;$HOME/.config/.bash_private\u0026#34; ] \u0026amp;\u0026amp; . \u0026#34;$HOME/.config/.bash_private\u0026#34; # Variables # --------- # List of directories to potentially add to PATH directories=(\u0026#34;$HOME/bin\u0026#34; \u0026#34;$HOME/.local/bin\u0026#34; \u0026#34;/usr/local/bin\u0026#34; \u0026#34;$HOME/git/ebdruplab/ansible-shared/scripts\u0026#34;) # Define a list of your SSH keys SSH_KEYS=(\u0026#34;id_rsa_example1\u0026#34; \u0026#34;access_example\u0026#34; \u0026#34;idexample\u0026#34;) # Initialize an array to hold the additional paths additional_paths=() # Loop through each directory and add it to the array if it exists for dir in \u0026#34;${directories[@]}\u0026#34;; do if [ -d \u0026#34;$dir\u0026#34; ]; then additional_paths+=(\u0026#34;$dir\u0026#34;) fi done # Add the additional paths to the PATH environment variable for path in \u0026#34;${additional_paths[@]}\u0026#34;; do PATH=\u0026#34;$PATH:$path\u0026#34; done # Export the updated PATH export PATH # Set the terminal colors # ----------------------- # Check if the hostname starts with \u0026#34;prod-\u0026#34; # https://robotmoon.com/bash-prompt-generator/ # https://ezprompt.net/ # Check if the hostname starts with \u0026#34;prod-\u0026#34; if [[ \u0026#34;$HOSTNAME\u0026#34; == prod-* ]]; then # If the user is root, set the PS1 prompt with red username and yellow hostname if [[ \u0026#34;$USER\u0026#34; == \u0026#34;root\u0026#34; ]]; then export PS1=\u0026#34;\\[$(tput setaf 9)\\]\\u\\[$(tput setaf 9)\\]@\\[$(tput setaf 9)\\]\\h\\[$(tput setaf 7)\\]:\\w\\[$(tput sgr0)\\]$ \u0026#34; else # If the user is not root, set the PS1 prompt with default username and yellow hostname export PS1=\u0026#34;\\[$(tput setaf 15)\\]\\u\\[$(tput setaf 9)\\]@\\[$(tput setaf 9)\\]\\h\\[ $(tput setaf 15)\\]:\\w\\[$(tput sgr0)\\]$ \u0026#34; fi fi # SSH # ---- # Startigng ssh agent and adding the id_rsa eval $(ssh-agent) \u0026gt;/dev/null # Loop through each key and add it if it exists for key in \u0026#34;${SSH_KEYS[@]}\u0026#34;; do key_path=\u0026#34;$HOME/.ssh/$key\u0026#34; if [ -f \u0026#34;$key_path\u0026#34; ]; then ssh-add \u0026#34;$key_path\u0026#34; 1\u0026gt;/dev/null fi done The .bash_public script:\n# file: .bash_public # Terminal Improvements # --------------------- # Setup # Nice to have alias cd_ebd=\u0026#39;cd ~/git/ebdruplab\u0026#39; # Then add to your .bash_profile # Install using sudo apt install xsel alias pbcopy=\u0026#39;xsel --clipboard --input\u0026#39; alias pbpaste=\u0026#39;xsel --clipboard --output\u0026#39; # Change strings alias toupper=\u0026#34;tr \u0026#39;[:lower:]\u0026#39; \u0026#39;[:upper:]\u0026#39;\u0026#34; alias tolower=\u0026#34;tr \u0026#39;[:upper:]\u0026#39; \u0026#39;[:lower:]\u0026#39;\u0026#34; # Source bash_profile alias resource=\u0026#39;source ~/.bash_profile\u0026#39; # List files alias ll=\u0026#39;ls -alhZ\u0026#39; # List files (reverse) alias llr=\u0026#39;ls -alhr\u0026#39; # List files by size alias lls=\u0026#39;ls -alhS\u0026#39; alias llsr=\u0026#39;ls -alhSr\u0026#39; # List files by date alias lld=\u0026#39;ls -alht\u0026#39; # List files by date (reverse) alias lldr=\u0026#39;ls -alhtr\u0026#39; # List files by date created alias lldc=\u0026#39;ls -alhtU\u0026#39; # List files by date created (reverse) alias lldcr=\u0026#39;ls -alhtUr\u0026#39; # List the file structure of the current directory alias ctree=\u0026#34;find . -print | sed -e \u0026#39;s;[^/]*/;|____;g;s;____|; |;g\u0026#39;\u0026#34; # NETWORKING # ----------- # myip: Public facing IP Address alias myip=\u0026#39;dig +short myip.opendns.com @resolver1.opendns.com\u0026#39; # netCons: Show all open TCP/IP sockets alias netCons=\u0026#39;lsof -i\u0026#39; # flushDNS: Flush out the DNS Cache alias flushDNS=\u0026#39;dscacheutil -flushcache\u0026#39; # lsock: Display open sockets alias lsock=\u0026#39;sudo /usr/sbin/lsof -i -P\u0026#39; # Require confirmation before overwriting target files. This setting keeps me from deleting things I didn\u0026#39;t expect to, etc alias cp=\u0026#39;cp -i\u0026#39; alias mv=\u0026#39;mv -i\u0026#39; alias rm=\u0026#39;rm -i\u0026#39; # Windows # ------- if grep -q microsoft /proc/version; then alias explorer=\u0026#34;explorer.exe .\u0026#34; fi # Functions # ----------- # Git fast track alias # Function to add, commit, and push changes to a Git repository # Usage: cgitadd \u0026#34;commit message\u0026#34; # # Args: # commit message (str): The commit message describing the changes. # # Returns: # None function cgitadd() { git add . git commit -m \u0026#34;$1\u0026#34; git push } # Display the current Git branch in your shell prompt function parse_git_branch() { git branch 2\u0026gt;/dev/null | sed -e \u0026#39;/^[^*]/d\u0026#39; -e \u0026#39;s/* \\(.*\\)/ (\\1)/\u0026#39; } # Get a quick overview of the status of your Git repository function gstatus() { git status -s } # Add all changes and commit them with a message function gcommit() { git add -A \u0026amp;\u0026amp; git commit -m \u0026#34;$*\u0026#34; } # Shows a concise git log function glog() { git log --pretty=format:\u0026#34;%h - %an, %ar : %s\u0026#34; } # List all branches and then checkout to a selected one function gcheckout() { git branch -a echo \u0026#34;Enter branch name:\u0026#34; read branch git checkout \u0026#34;$branch\u0026#34; } # Pull the latest changes with rebase function gpull() { git pull --rebase } # Create and switch to a new branch function gbranch() { git checkout -b \u0026#34;$*\u0026#34; } # Push a new branch to remote and set upstream function gpushnew() { git push -u origin \u0026#34;$(git branch --show-current)\u0026#34; } # Delete local branches that have been merged into the current branch function gclean() { git branch --merged | egrep -v \u0026#34;(^\\*|master|dev)\u0026#34; | xargs git branch -d } # Show git diff with word-level differences function gdiff() { git diff --color-words \u0026#34;$*\u0026#34; } # extract: Extract most know archives with one command function extract() { if [ -f $1 ]; then case $1 in *.tar.bz2) tar xjf $1 ;; *.tar.gz) tar xzf $1 ;; *.bz2) bunzip2 $1 ;; *.rar) unrar e $1 ;; *.gz) gunzip $1 ;; *.tar) tar xf $1 ;; *.tbz2) tar xjf $1 ;; *.tgz) tar xzf $1 ;; *.zip) unzip $1 ;; *.Z) uncompress $1 ;; *.7z) 7z x $1 ;; *.ztd) tar --use-compress-program=unzstd -xvf $1 ;; *) echo \u0026#34;\u0026#39;$1\u0026#39; cannot be extracted via extract()\u0026#34; ;; esac else echo \u0026#34;\u0026#39;$1\u0026#39; is not a valid file\u0026#34; fi } function data_usage() { du -sh --exclude=\u0026#39;/proc/*\u0026#39; --exclude=\u0026#39;/tmp/*\u0026#39; --exclude=\u0026#39;/var/*\u0026#39; /* 2\u0026gt;/dev/null | sort -hr } # SSH Functions function pssh() { local user=${1:-root} ssh -l \u0026#34;$user\u0026#34; -o PreferredAuthentications=password -o PubkeyAuthentication=no \u0026#34;${@:2}\u0026#34; } function issh() { local user=${1:-root} ssh -l \u0026#34;$user\u0026#34; -i ~/.ssh/example_key \u0026#34;${@:2}\u0026#34; } # Function # -------- # Private Automation Hub publish_collection() { if [[ -z \u0026#34;$1\u0026#34; ]]; then echo \u0026#34;You need to provide a collection archive file as an argument.\u0026#34; else ansible-galaxy collection publish \u0026#34;$1\u0026#34; --api-key=\u0026#34;$AUTOMATIONHUB_API_KEY\u0026#34; -s \u0026#34;$AUTOMATIONHUB_SERVER\u0026#34; fi } install_collection() { if [[ -z \u0026#34;$1\u0026#34; ]]; then echo \u0026#34;You need to provide a collection name as an argument.\u0026#34; echo \u0026#34;Usage: install_collection namespace/collection_name [--force]\u0026#34; else if [[ \u0026#34;$2\u0026#34; == \u0026#34;--force\u0026#34; ]]; then ansible-galaxy collection install \u0026#34;$1\u0026#34; --api-key=\u0026#34;$AUTOMATIONHUB_API_KEY\u0026#34; -s \u0026#34;https://\u0026lt;HUB_URL\u0026gt;/api/galaxy/content/\u0026lt;content_location\u0026gt;/\u0026#34; --force else ansible-galaxy collection install \u0026#34;$1\u0026#34; --api-key=\u0026#34;$AUTOMATIONHUB_API_KEY\u0026#34; -s \u0026#34;https://\u0026lt;HUB_URL\u0026gt;/api/galaxy/\u0026#34; fi fi } The .bash_private script:\n# file: .bash_private # EXPORTS # ------- export SAT_USERNAME=\u0026lt;USERNAME\u0026gt; export AUTOMATIONHUB_API_KEY=\u0026lt;API_KEY\u0026gt; export AUTOMATIONHUB_SERVER=\u0026lt;Hub_sever\u0026gt; Then to set correct file ownership:\nchmod 0700 .config .config/.bash_private .config/.bash_public .bash_profile chown $USER:$USER .config .config/.bash_private .config/.bash_public .bash_profile ","date":"28 April 2024","externalUrl":null,"permalink":"/posts/02-linux/dot_files/linux-dot-config/","section":"IT Projects and Resources","summary":"dot files for linux # In this guide I will provide you with info on how i setup my .","title":"Linux dot config","type":"posts"},{"content":" Linux Cheat Sheets commands # This contains different heloers for commands on a linux os.\nUnix Command-Line Utilities Cheat-Sheet # Using Cron and placing crontab files # CRON Fields # Field Allowed Values Description MINUTE 0-59 Trigger every MINUTE minute(s) HOUR 0-23 Trigger every HOUR hour(s) DAY OF MONTH 1-31 Trigger on specific DAY of the month MONTH 1-12 Trigger in MONTH month(s) DAY OF WEEK 0-6 (Sun-Sat) Trigger on specific DAY OF WEEK, where Sunday = 0 Special Characters in CRON # Special Character Description * Represents all possible values for the field , Separates items in a list - Specifies a range of values / Specifies increments CRON Expression Examples # Cron Expression Description * * * * * Executes every minute 0 * * * * Executes on the hour every hour 0 0 * * * Executes at midnight every day 0 0 1 * * Executes at midnight on the first of every month 30 20 * * 6 Executes at 8:30 PM every Saturday */5 * * * * Executes every five minutes 0 0 8-10 * * * Executes on the hour every hour from 8 AM to 10 AM Executing a Script and Redirecting Output to a Log File # 0 5 * * * /path/to/script.sh \u0026gt;\u0026gt; /path/to/logfile.log 2\u0026gt;\u0026amp;1 This CRON job example runs a script located at /path/to/script.sh every day at 5 AM, appending both standard output and standard error to /path/to/logfile.log.\nCommon CRON Directories and Files # Location/File Description /etc/crontab System-wide crontab file where administrators can define CRON jobs. /etc/cron.d Directory for additional system-wide cron job files. CRON jobs in this directory allow for easier management of individual cron job configurations. /etc/cron.daily Directory for scripts that need to run daily. /etc/cron.hourly Directory for scripts that need to run hourly. /etc/cron.weekly Directory for scripts that need to run weekly. /etc/cron.monthly Directory for scripts that need to run monthly. /var/spool/cron/crontabs Directory where individual user crontab files are stored. Users can schedule their personal jobs using the crontab command. /etc/cron.allow File containing usernames that are allowed to use crontab. If this file exists, only users listed in it can schedule cron jobs. /etc/cron.deny File containing usernames that are denied access to crontab. If cron.allow does not exist, all users except those listed in cron.deny can schedule jobs. Example of Adding a System-Wide CRON Job # To add a system-wide CRON job, you might place a file in /etc/cron.d/. Here’s an example of what the contents might look like:\n# Example CRON job in /etc/cron.d/myjob 0 5 * * * root /usr/local/bin/daily-task.sh MySQL Cheat-Sheet # Connect to MySQL # Command Description mysql -u root -p Connect to MySQL as root user mysql -u \u0026lt;user\u0026gt; -p Connect to MySQL as a specific user mysql -u root -p -h \u0026lt;host\u0026gt; Connect to MySQL on a specific host Backup and Restore # Command Description mysqldump -u root -p \u0026lt;database\u0026gt; \u0026gt; backup.sql Backup a database to a file mysql -u root -p \u0026lt;database\u0026gt; \u0026lt; backup.sql Restore a database from a file PostgreSQL Cheat-Sheet # Connect to PostgreSQL # Command Description psql -U postgres Connect to PostgreSQL as the postgres user psql -U \u0026lt;user\u0026gt; -d \u0026lt;database\u0026gt; Connect to PostgreSQL as a specific user and database psql -U \u0026lt;user\u0026gt; -d \u0026lt;database\u0026gt; -h \u0026lt;host\u0026gt; Connect to PostgreSQL on a specific host PostreSQL CLI Commands # Command Description \\c \u0026lt;database\u0026gt; Connect to a specific database \\password \u0026lt;user\u0026gt; Change password for a specific user \\l List all databases \\d+ Show detailed information about various database objects \\dt List all tables in the current database \\du List all users \\df List all functions \\dv List all views \\dn List all schemas \\dp List all permissions \\di List all indexes \\ds List all sequences \\d+ Show detailed information about various database objects \\q Quit psql \\x Toggle expanded output Backup and Restore # Command Description pg_dump \u0026lt;database\u0026gt; \u0026gt; backup.sql Backup a database to a file psql \u0026lt;database\u0026gt; \u0026lt; backup.sql Restore a database from a file Patterns # Grep Cheat-Sheet # Command Description grep 'pattern' file Search for a pattern in a file grep -i 'pattern' file Case insensitive search grep -r 'pattern' dir Recursively search for a pattern in all files under the directory grep -v 'pattern' file Invert match to display lines that do not contain the pattern grep -n 'pattern' file Display the line numbers with the output grep -c 'pattern' file Count the number of lines that match the pattern grep -l 'pattern' * Show only the names of files with matching lines grep -L 'pattern' * Show only the names of files without matching lines grep -o 'pattern' file Show only the part of a line matching the pattern grep 'pattern1|pattern2' file Search for lines matching pattern1 or pattern2 grep -A 3 'pattern' file Display 3 lines after the matching line grep -B 3 'pattern' file Display 3 lines before the matching line grep -C 3 'pattern' file Display 3 lines before and after the matching line grep '^pattern' file Match lines beginning with \u0026lsquo;pattern\u0026rsquo; grep 'pattern$' file Match lines ending with \u0026lsquo;pattern\u0026rsquo; grep '^[^#]' file Ignore lines starting with \u0026lsquo;#\u0026rsquo; (comments) `grep -E \u0026lsquo;patt(ern1 ern2)\u0026rsquo; file` grep -w 'pattern' file Match whole word \u0026lsquo;pattern\u0026rsquo; grep -f patterns.txt file Use patterns from the file, one per line grep -e 'pattern1' -e 'pattern2' file Search for multiple patterns SED Cheat-Sheet # Command Description sed 's/pattern/replacement/' file Replace the first occurrence of a pattern in each line sed -i 's/pattern/replacement/' file Replace all occurrences of a pattern in the file (in-place editing) sed '/pattern/d' file Delete lines that match the pattern sed '2d' file Delete the second line of the file sed '2,$d' file Delete from the second line to the end of the file sed 's/pattern/replacement/g' file Replace all occurrences of a pattern in each line sed -n 'p' file Print the output (useful with -n to suppress other output) sed '/pattern/p' file Print only lines that match the pattern sed '1,5s/pattern/replacement/' file Apply the substitution to lines 1 to 5 only sed -e 'command1' -e 'command2' file Apply multiple editing commands in sequence sed '5q' file Print until the 5th line of the file then quit sed 's/[a-z]/\\U\u0026amp;/g' file Convert lowercase letters to uppercase SORT Cheat-Sheet # Command Description sort file Sort lines of text alphabetically in a file sort -n file Sort numerically (useful for sorting numbers) sort -r file Reverse the results of sorts (descending order) sort -o output_file file Write the result to the output_file instead of standard output sort -k 2 file Sort a file based on the second column of data sort -u file Sort and remove duplicate lines sort -t':' -k 3n file Sort a file using \u0026lsquo;:\u0026rsquo; as a delimiter and numerically by the third column sort -f file Ignore case while sorting sort -m file1 file2 Merge already sorted files file1 and file2 sort -c file Check whether the file is already sorted; do not sort AWK Cheat-Sheet # Command Description awk '/pattern/ {print $1}' standard Unix shells awk '/pattern/ {print \u0026quot;$1\u0026quot;}' compiled with DJGPP, Cygwin awk \u0026quot;/pattern/ {print \\\u0026quot;$1\\\u0026quot;}\u0026quot; GnuWin32, UnxUtils, Mingw awk '1;{print \u0026quot;\u0026quot;}' double space a file awk 'BEGIN{ORS=\u0026quot;\\n\\n\u0026quot;};1' double space a file awk 'NF{print $0 \u0026quot;\\n\u0026quot;}' double space a file which already has blank lines awk '1;{print \u0026quot;\\n\u0026quot;}' triple space a file awk '{print FNR \u0026quot;\\t\u0026quot; $0}' files* precede each line by its line number awk '{print NR \u0026quot;\\t\u0026quot; $0}' files* precede each line by its line number for all files together awk '{printf(\u0026quot;%5d : %s\\n\u0026quot;, NR,$0)}' number each line of a file awk 'NF{$0=++a \u0026quot; :\u0026quot; $0};1' number each line of a file, but only print numbers if line is not blank awk 'END{print NR}' count lines (emulates \u0026ldquo;wc -l\u0026rdquo;) awk '{s=0; for (i=1; i\u0026lt;=NF; i++) s=s+$i; print s}' print the sums of the fields of every line awk '{for (i=1; i\u0026lt;=NF; i++) s=s+$i}; END{print s}' add all fields in all lines and print the sum awk '{for (i=1; i\u0026lt;=NF; i++) if ($i \u0026lt; 0) $i = -$i; print }' print every line after replacing each field with its absolute value awk '{for (i=1; i\u0026lt;=NF; i++) $i = ($i \u0026lt; 0) ? -$i : $i; print }' print every line after replacing each field with its absolute value awk '{ total = total + NF }; END {print total}' file print the total number of fields (\u0026ldquo;words\u0026rdquo;) in all lines awk '/Beth/{n++}; END {print n+0}' file print the total number of lines that contain \u0026ldquo;Beth\u0026rdquo; awk '$1 \u0026gt; max {max=$1; maxline=$0}; END{ print max, maxline}' print the largest first field and the line that contains it awk '{ print NF \u0026quot;:\u0026quot; $0 }' print the number of fields in each line, followed by the line awk '{ print $NF }' print the last field of each line awk '{ field = $NF }; END{ print field }' print the last field of the last line awk 'NF \u0026gt; 4' print every line with more than 4 fields awk '$NF \u0026gt; 4' print every line where the value of the last field is \u0026gt; 4 Network # Ethtool Cheat-Sheet # Displaying Information # Command Description ethtool \u0026lt;interface\u0026gt; Display information about a specific network interface ethtool -i \u0026lt;interface\u0026gt; Display driver information ethtool -a \u0026lt;interface\u0026gt; Display all settings ethtool -k \u0026lt;interface\u0026gt; Display offload settings ethtool -c \u0026lt;interface\u0026gt; Display coalescing settings ethtool -g \u0026lt;interface\u0026gt; Display ring buffer settings ethtool -l \u0026lt;interface\u0026gt; Display large receive offload settings ethtool -S \u0026lt;interface\u0026gt; Display statistics ethtool -t \u0026lt;interface\u0026gt; Test the network interface for offloading capabilities ethtool -T \u0026lt;interface\u0026gt; Display time stamping settings ethtool -x \u0026lt;interface\u0026gt; Display channel settings ethtool -P \u0026lt;interface\u0026gt; Display permanent MAC address ethtool -N \u0026lt;interface\u0026gt; Display offload settings ethtool -u \u0026lt;interface\u0026gt; Display bus information ethtool -d \u0026lt;interface\u0026gt; Display register dump ethtool -g \u0026lt;interface\u0026gt; Display ring buffer settings Setting Parameters # Command Description ethtool -G \u0026lt;interface\u0026gt; Set ring buffer settings ethtool -L \u0026lt;interface\u0026gt; Set large receive offload settings ethtool -A \u0026lt;interface\u0026gt; Set pause parameters ethtool -C \u0026lt;interface\u0026gt; Set coalescing settings ethtool -K \u0026lt;interface\u0026gt; Set offload settings ethtool -N \u0026lt;interface\u0026gt; Set offload settings ethtool -p \u0026lt;interface\u0026gt; Blink the LED on the network interface ethtool -r \u0026lt;interface\u0026gt; Reset the network interface ARP in Linux # Command Description arp View the ARP table arp -a View the ARP table arp -n View the ARP table (don\u0026rsquo;t resolve names) arp -d \u0026lt;ip\u0026gt; Delete an entry from the ARP table arp -s \u0026lt;ip\u0026gt; \u0026lt;mac_address\u0026gt; Add an entry to the ARP table arp -i \u0026lt;interface\u0026gt; -s \u0026lt;ip\u0026gt; \u0026lt;mac_address\u0026gt; Add an entry to the ARP table for a specific interface arp -i \u0026lt;interface\u0026gt; -d \u0026lt;ip\u0026gt; Delete an entry from the ARP table for a specific interface arp -i \u0026lt;interface\u0026gt; -n View the ARP table for a specific interface arp -i \u0026lt;interface\u0026gt; -a View the ARP table for a specific interface ip neigh show View the ARP table ip neigh show \u0026lt;ip\u0026gt; View the ARP table for a specific IP address ip neigh add \u0026lt;ip\u0026gt; lladdr \u0026lt;mac_address\u0026gt; dev \u0026lt;interface\u0026gt; Add an entry to the ARP table ip neigh change \u0026lt;ip\u0026gt; lladdr \u0026lt;mac_address\u0026gt; dev \u0026lt;interface\u0026gt; Change an entry in the ARP table ip neigh del \u0026lt;ip\u0026gt; dev \u0026lt;interface\u0026gt; Delete an entry from the ARP table ip neigh flush dev \u0026lt;interface\u0026gt; Flush the ARP table for a specific interface ip neigh flush all Flush the ARP table ip -s neigh show Show ARP statistics ip -s neigh flush all Flush the ARP cache Linux One-Liners # This table provides useful one-liner commands for Linux users, ideal for system administration and development tasks.\nCommand Description ps auxf | sort -nr -k 3 | head -10 Display a tree of system processes, sorted by memory usage. df -h Check available disk space on all mounted filesystems in a human-readable format. top Monitor real-time system processes. lsof -p $$ List all open files by a specific process (replace $$ with the process ID). wc -l filename Count the number of lines in a file named filename. sort -n -t . -k 1,1 -k 2,2 -k 3,3 -k 4,4 file Sort a list of IP addresses stored in a file. sort file | uniq -c | sort -nr | head Find the most frequently occurring lines in a file, useful for log analysis. netstat -tuln Check all listening ports on the system. wget --mirror -p --convert-links -P ./LOCAL-DIR website-url Download a website and all of its assets for offline viewing, storing in LOCAL-DIR. tar czf backup.tar.gz /path/to/directory Create a compressed backup of a directory. newuser=\u0026quot;xyzuser\u0026quot; \u0026amp;\u0026amp; sudo useradd -m $newuser \u0026amp;\u0026amp; echo \u0026quot;$newuser ALL=(ALL) NOPASSWD: ALL\u0026quot; | sudo tee /etc/sudoers.d/$newuser Create a new user defined by newuser, and add a sudoers file for them with NOPASSWD enabled. ls -lhtr --color=always Sort by last writen to reverse ","date":"19 May 2024","externalUrl":null,"permalink":"/posts/02-linux/linux-commands/bash/","section":"IT Projects and Resources","summary":"Linux Cheat Sheets commands # This contains different heloers for commands on a linux os.","title":"Linux Cheat Sheets commands","type":"posts"},{"content":" Mastering Load Balancing with Nginx and HAProxy # Introduction # Load balancing is a critical component for distributing internet traffic across multiple servers, ensuring that your website or application can handle large amounts of traffic without a hitch. Both Nginx and HAProxy are powerful tools for this task, each offering unique features and configurations. This guide explores six popular load balancing strategies implemented with both Nginx and HAProxy, using example.com as our sample domain. This will help you choose and implement the right strategy based on your specific needs.\nExamples on diffrent types # we\u0026rsquo;ll explore six dynamic load balancing methods designed to distribute network traffic efficiently across server resources. From the simple Round Robin approach, ensuring even load distribution, to the sophisticated Least Time strategy, prioritizing servers with the quickest response times, each technique offers unique benefits to enhance system performance and reliability. Get ready to delve into the nuances of each method to find the best fit for your infrastructure needs.\n1. Round Robin # Nginx Configuration: # Round Robin is the simplest form of load balancing, distributing requests equally across all available servers.\nhttp { upstream backend { server server1.example.com; server server2.example.com; server server3.example.com; } server { listen 443; server_name example.com www.example.com; location / { proxy_pass http://backend; } } } HAProxy Configuration: # HAProxy also supports Round Robin by default when no balancing algorithm is specified.\nfrontend http_front bind *:443 default_backend http_back backend http_back balance roundrobin server server1 server1.example.com:443 check server server2 server2.example.com:443 check server server3 server3.example.com:443 check 2. Sticky Sessions # Nginx Configuration: # Using IP Hash for maintaining client-server stickiness.\nhttp { upstream backend { ip_hash; server server1.example.com; server server2.example.com; server server3.example.com; } server { listen 443; server_name example.com www.example.com; location / { proxy_pass http://backend; } } } HAProxy Configuration: # Utilizing cookies to ensure sticky sessions.\nfrontend http_front bind *:443 default_backend http_back backend http_back balance roundrobin cookie SERVERID insert indirect nocache server server1 server1.example.com:443 check cookie server1 server server2 server2.example.com:443 check cookie server2 server server3 server3.example.com:443 check cookie server3 3. Weighted Round Robin # Nginx Configuration: # Adjusting server weights based on their capacity.\nhttp { upstream backend { server server1.example.com weight=5; server server2.example.com weight=1; server server3.example.com weight=1; } server { listen 443; server_name example.com www.example.com; location / { proxy_pass http://backend; } } } HAProxy Configuration: # Similar weighting in HAProxy to manage server load based on performance.\nfrontend http_front bind *:443 default_backend http_back backend http_back balance roundrobin server server1 server1.example.com:443 check weight 5 server server2 server2.example.com:443 check weight 1 server server3 server3.example.com:443 check weight 1 4. IP/URL Hash # Nginx Configuration: # Distributing requests based on client IP or URL hash.\nhttp { upstream backend { hash $remote_addr consistent; server server1.example.com; server server2.example.com; server server3.example.com; } server { listen 443; server_name example.com www.example.com; location / { proxy_pass http://backend; } } } HAProxy Configuration: # Using source IP to maintain a consistent server routing.\nfrontend http_front bind *:443 default_backend http_back backend http_back balance source server server1 server1.example.com:443 check server server2 server2.example.com:443 check server server3 server3.example.com:443 check 5. Least Connections # Nginx Configuration: # Directing traffic to the server with the fewest active connections.\nhttp { upstream backend { least_conn; server server1.example.com; server server2.example.com; server server3.example.com; } server { listen 443; server_name example.com www.example.com; location / { proxy_pass http://backend; } } } HAProxy Configuration: # Optimizing connection distribution with the least connections method.\nfrontend http_front bind *:443 default_backend http_back backend http_back balance leastconn server server1 server1.example.com:443 check server server2 server2.example.com:443 check server server3 server3.example.com:443 check Conclusion # Both Nginx and HAProxy offer robust solutions for load balancing with various algorithms to suit different scenarios. Choosing the right tool and strategy depends on your specific requirements, such as the need for advanced features like health checks or the simplicity of setup and maintenance. By understanding these examples, you can better plan and implement a load balancing solution that ensures high availability and optimal performance for your applications.\n","date":"19 June 2024","externalUrl":null,"permalink":"/posts/02-linux/loadbalancing/load-balancing-nginx-haproxy/","section":"IT Projects and Resources","summary":"Mastering Load Balancing with Nginx and HAProxy # Introduction # Load balancing is a critical component for distributing internet traffic across multiple servers, ensuring that your website or application can handle large amounts of traffic without a hitch.","title":"Mastering Load Balancing with Nginx and HAProxy","type":"posts"},{"content":" Windows Subsystem for Linux (WSL) # WSL is Linux on Windows. It is free and there are multiple OS\u0026rsquo;es you can get.\nPS C:\\Users\\ebdruplab\u0026gt; wsl --list --online The following is a list of valid distributions that can be installed. Install using \u0026#39;wsl --install -d \u0026lt;Distro\u0026gt;\u0026#39;. NAME FRIENDLY NAME Ubuntu Ubuntu Debian Debian GNU/Linux kali-linux Kali Linux Rolling Ubuntu-18.04 Ubuntu 18.04 LTS Ubuntu-20.04 Ubuntu 20.04 LTS Ubuntu-22.04 Ubuntu 22.04 LTS Ubuntu-24.04 Ubuntu 24.04 LTS OracleLinux_7_9 Oracle Linux 7.9 OracleLinux_8_7 Oracle Linux 8.7 OracleLinux_9_1 Oracle Linux 9.1 openSUSE-Leap-15.5 openSUSE Leap 15.5 SUSE-Linux-Enterprise-Server-15-SP4 SUSE Linux Enterprise Server 15 SP4 SUSE-Linux-Enterprise-15-SP5 SUSE Linux Enterprise 15 SP5 openSUSE-Tumbleweed openSUSE Tumbleweed Installation # To get the best expirence from WSL plece install windows terminal.\nAfter that come back to this guide.\nOpen Windows Terminal write the command wsl --install -d Ubuntu (change Ubuntu to what ever you wan\u0026rsquo;t from the list gotten) wsl --update You will be asked to give a Username and Password. As this is a dev env I would highly recommend doing the following\ntouch /home/$USER/.hushlogin USERNAME=\u0026quot;ebdruplab\u0026quot;;echo \u0026quot;$USERNAME ALL=(ALL) NOPASSWD: ALL\u0026quot; | sudo tee \u0026quot;/etc/sudoers.d/$USERNAME\u0026quot; \u0026gt;/dev/null First time you will be asked for your password Setup your dotfile, my setup can be found Linux dot Files Setup your wsl config file sudo vi /etc/wsl.conf [boot] systemd=true [wsl2] memory = 18GB processors = 16 # Makes the WSL 2 VM use six virtual processors (4 Cores x 8 Threads) x 1 CPU = 32 vCPUs Upgrade and update system: sudo apt-get update -y \u0026amp;\u0026amp; sudo apt-get upgrade -y Configuration # You can configure your windows terminal, but right now this is out of scope of this blog post, maybe I\u0026rsquo;ll add it later\nWSL Cheat-Sheet # Backup and Restore WSL # Command Description wsl --list --verbose List Running Distros wsl --distribution \u0026lt;distro\u0026gt; Start/Restart a Distro wsl --t \u0026lt;distro\u0026gt; Terminate a Running Distro wsl --shutdown Terminate All Running Distros and WSL process wsl --export (distribution) (filename.tar) Backup a WSL Distro wsl --import (distribution) (install location) (file location and filename) Restore a WSL Distro from Backup Symbolic Links # Command Description sudo ln -s /mnt/c/Users/\u0026lt;user\u0026gt;/.ssh ~/.ssh Link .ssh folder sudo ln -s /mnt/c/Users/\u0026lt;user\u0026gt;/.kube ~/.kube Link .kube folder Networking # Command Description netsh interface portproxy add v4tov4 listenport=$port connectport=$port connectaddress=$remoteaddr Add Port Forwarding netsh advfirewall firewall add rule name=$port dir=in action=allow protocol=TCP localport=$port Add Firewall Rule netsh interface portproxy delete v4tov4 listenport=$port Delete PortForwarding netsh advfirewall firewall delete rule name=$port Delete Firewall Rule netsh interface portproxy show v4tov4 Show PortForwardings Setup pbcopy and pbpaste on WSL # This is mac native and can be setup on wsl 2\nsudo apt install xsel # Then add to your .bash_profile # Install using sudo apt install xsel alias pbcopy=\u0026#39;xsel --clipboard --input\u0026#39; alias pbpaste=\u0026#39;xsel --clipboard --output\u0026#39; ","date":"5 May 2024","externalUrl":null,"permalink":"/posts/03-windows/wsl/windows-subsystem-linux/","section":"IT Projects and Resources","summary":"Windows Subsystem for Linux (WSL) # WSL is Linux on Windows.","title":"Windows Subsystem for Linux (WSL)","type":"posts"},{"content":" Visual Studio Code Shortcuts Guide # One of the key features that make Visual Studio Code (VS Code) a favorite among developers is its extensive set of keyboard shortcuts. These shortcuts can significantly enhance productivity by allowing you to perform actions quickly without leaving the keyboard. Below is a table listing some of the most useful shortcuts for VS Code.\nAction Shortcut (Windows) Command Palette Ctrl + Shift + P Quick Open Ctrl + P New File Ctrl + N Open File Ctrl + O Save Ctrl + S Save All Ctrl + K, S Close Editor Ctrl + W Close All Editors Ctrl + K, W Split Editor Ctrl + \\ Toggle Terminal `Ctrl + `` Toggle Sidebar Ctrl + B Toggle Full Screen F11 Find Ctrl + F Replace Ctrl + H Find in Files Ctrl + Shift + F Replace in Files Ctrl + Shift + H Go to Definition F12 Peek Definition Alt + F12 Rename Symbol F2 Show Hover Ctrl + K, Ctrl + I Open Settings Ctrl + , Open Keyboard Shortcuts Ctrl + K, Ctrl + S Open Extensions Ctrl + Shift + X Comment Line Ctrl + / Block Comment Shift + Alt + A Move Line Up/Down Alt + Up/Down Arrow Copy Line Up/Down Shift + Alt + Up/Down Open/focus terminal Ctrl + æ Focus Explorer Ctrl + Shift + E These shortcuts cover a wide range of functionalities, from navigating the code to performing complex refactoring tasks. Learning and incorporating these into your workflow can make your development process much smoother and more efficient.\nInstalled Extensions in Visual Studio Code # Visual Studio Code\u0026rsquo;s extensibility allows you to tailor your development environment to suit your specific needs. Here is a detailed list of some powerful extensions that are currently installed in your VS Code instance:\n1. Continue (continue.continue) # Description: Continue is an AI-powered code assistant that helps you write and understand code faster. It leverages advanced machine learning models to suggest code completions, generate documentation, and provide intelligent insights into your codebase. Usage: This extension can be particularly useful for speeding up development by providing context-aware code suggestions. I have setup a ollama installation for use with this plugin. 2. Dracula Official (dracula-theme.theme-dracula) # Description: Dracula is a popular, dark theme for various editors and platforms. It offers a visually appealing and consistent color scheme that reduces eye strain and makes the code easier to read. Usage: Ideal for developers who prefer working in a dark-themed environment, enhancing focus and reducing eye fatigue. 3. Indent Rainbow (oderwat.indent-rainbow) # Description: Indent Rainbow colorizes the indentation levels in your code with different colors, making it easier to identify the structure and nested blocks of code. Usage: Particularly useful for languages with significant indentation, like Python, or for large code files where visualizing nested structures quickly is essential. 4. Ansible (redhat.ansible) # Description: This extension provides rich support for Ansible, including features like syntax highlighting, IntelliSense, and linting for Ansible playbooks, roles, and variables. Usage: Essential for developers working with Ansible automation, ensuring accurate and efficient Ansible script development. 5. YAML (redhat.vscode-yaml) # Description: This extension offers comprehensive support for YAML files, including features like validation, autocompletion, and error detection. Usage: Crucial for developers who frequently work with YAML configuration files, ensuring the correctness and efficiency of their YAML scripts. 6. VSCode Icons (vscode-icons-team.vscode-icons) # Description: Adds a set of visually appealing icons to VS Code, making it easier to identify files and directories at a glance. Usage: Enhances the visual organization of your project, making it easier to navigate and manage your files. 7. Zoom Bar (wraith13.zoombar-vscode) # Description: Adds a zoom bar to VS Code, allowing you to quickly zoom in and out of your code. Usage: Useful for presentations, pair programming, or simply adjusting the code view for better readability. 8. Markdown Preview GitHub Styles (bierner.markdown-preview-github-styles) # Description: Renders Markdown previews in VS Code with GitHub-like styles, providing a more consistent look with how Markdown files are displayed on GitHub. Usage: Ideal for developers writing documentation or README files that need to look the same as they would on GitHub. 9. Markdown All in One (yzhang.markdown-all-in-one) # Description: An all-in-one extension for Markdown, providing features like shortcuts, table of contents generation, and more. Usage: Makes writing and managing Markdown files easier and more efficient with a comprehensive set of tools. 10. Trailing Spaces (shardulm94.trailing-spaces) # Description: Highlights trailing spaces in your code and provides commands to delete them. Usage: Helps maintain clean code by ensuring no unnecessary trailing spaces are left in the code files. 11. File Tree Generator (shinotatwu-ds.file-tree-generator) # Description: Generates a file tree structure of your project directory for easy visualization and documentation. Usage: Useful for creating visual representations of your project structure, which can be included in documentation or shared with team members. One-Liner to Install All Extensions (PowerShell) # To install all these extensions in VS Code using PowerShell, run the following command:\ncode --install-extension continue.continue; code --install-extension dracula-theme.theme-dracula; code --install-extension oderwat.indent-rainbow; code --install-extension redhat.ansible; code --install-extension redhat.vscode-yaml; code --install-extension vscode-icons-team.vscode-icons; code --install-extension wraith13.zoombar-vscode; code --install-extension bierner.markdown-preview-github-styles; code --install-extension yzhang.markdown-all-in-one; code --install-extension shardulm94.trailing-spaces; code --install-extension shinotatwu-ds.file-tree-generator ","date":"27 July 2024","externalUrl":null,"permalink":"/posts/03-windows/vscode/vs-code/","section":"IT Projects and Resources","summary":"Visual Studio Code Shortcuts Guide # One of the key features that make Visual Studio Code (VS Code) a favorite among developers is its extensive set of keyboard shortcuts.","title":"Visual Studio Code","type":"posts"},{"content":" Markdown # Markdown is a text-to-HTML conversion tool for web writers. Markdown allows you to write using an easy-to-read, easy-to-write plain text format, then convert it to structurally valid XHTML (or HTML).\nDocumentation: Markdown Docs RFC: RFC 7763 GitHub Documentation: Writing Markdown on GitHub\nCheat-Sheet # Headings # # Heading 1 ## Heading 2 ### Heading 3 #### Heading 4 ##### Heading 5 ###### Heading 6 Here is a heading: # Heading, don\u0026rsquo;t do this: #Heading\nEmphasis # Emphasis, aka italics, with *asterisks* or _underscores_. Strong emphasis, aka bold, with **asterisks** or __underscores__. Combined emphasis with **asterisks and _underscores_**. Strikethrough uses two tildes. ~~Scratch this.~~ Line Breaks # First line with two spaces after. And the next line. Lists # Ordered Lists # 1. First item 2. Second item 3. Third item Unordered Lists # - First item - Second item - Third item Links # Link with text: [link-text](https://www.google.com) Images # Image with alt text: ![alt-text](https://camo.githubusercontent.com/4d89cd791580bfb19080f8b0844ba7e1235aa4becc3f43dfd708a769e257d8de/68747470733a2f2f636e642d70726f642d312e73332e75732d776573742d3030342e6261636b626c617a6562322e636f6d2f6e65772d62616e6e6572342d7363616c65642d666f722d6769746875622e6a7067) Image without alt text: ![](https://camo.githubusercontent.com/4d89cd791580bfb19080f8b0844ba7e1235aa4becc3f43dfd708a769e257d8de/68747470733a2f2f636e642d70726f642d312e73332e75732d776573742d3030342e6261636b626c617a6562322e636f6d2f6e65772d62616e6e6572342d7363616c65642d666f722d6769746875622e6a7067) Code Blocks # Inline Code Block # Inline `code` has `back-ticks around` it. Blocks of Code # ```javascript var s = \"JavaScript syntax highlighting\"; alert(s); ``` ```python s = \"Python syntax highlighting\" print s ``` ``` No language indicated, so no syntax highlighting. But let's throw in a tag. ``` Tables # There must be at least 3 dashes separating each header cell. The outer pipes (|) are optional, and you don\u0026rsquo;t need to make the raw Markdown line up prettily.\n| Heading 1 | Heading 2 | Heading 3 | |---|---|---| | col1 | col2 | col3 | | col1 | col2 | col3 | ","date":"15 April 2024","externalUrl":null,"permalink":"/posts/04-misc/markdown_help/markdown-help/","section":"IT Projects and Resources","summary":"Markdown # Markdown is a text-to-HTML conversion tool for web writers.","title":"Markdown Help","type":"posts"},{"content":" Jekyll # Jekyll is a static site generator, and is easy and fast to setup\nInstallation # This has been done on wsl2\n# WSL2 install - ubuntu sudo apt-get update -y \u0026amp;\u0026amp; sudo apt-get upgrade -y sudo apt-get install ruby-full sudo gem update --system sudo apt-get install build-essential --no-install-recommends sudo gem install jekyll bundler # Go to docs root location e.g you github.io location bundler bundle exec jekyll serve ","date":"27 April 2024","externalUrl":null,"permalink":"/posts/04-misc/jekyll_help/jekyll-setup/","section":"IT Projects and Resources","summary":"Jekyll # Jekyll is a static site generator, and is easy and fast to setup","title":"Jekyll Setup","type":"posts"},{"content":" Links # On this post I will provide you with different links, good for graphical arts and IT.\nLinks For Graphic Arts, and Items That Might Help # Converters # Ezgif - converter and more Convertio - convert different files Gifs # Giphy - gif generator Steam Backgrounds # Backgrounds - Steam Free Logos, Icons and More # icons8 - favicons, png and more for free (but restricted) Freepik IT Links # Web Development # Wiki Webpages # Wiki.JS Frameworks # Laravel Django Icons Generators # Generate Favicons Open Source # SNMP Monitoring Software # Zabbix :: The Enterprise-Class Open Source Network Monitoring Solution Network Management - Castle Rock Computing - SNMPc Free SNMP Monitoring Software with SNMP v3 Support NetXMS - Open-source network and infrastructure monitoring and management system Pandora FMS: Open Source Monitoring Software Cluster (DFS) # Gluster - Storage for Your Cloud Firewall # pfSense® - World\u0026rsquo;s Most Trusted Open Source Firewall OPNsense® a true open source security platform and more - OPNsense® is a true open source firewall and more Untangle: Network Security for SMB Intrusion Detection # RITA SNORT IT Asset Management # FOG Project (Win, Linux support) Snipe-IT Free Open Source IT Asset Management Netbox LDAP Server # OpenLDAP phpLDAPadmin Hypervisor # XCP-ng ESXI Server - Maximum 1 CPU and 32 GB RAM ARM ESXI Cluster Management # Kubernetes k8 and k3 OKD - Upstream OpenShift Database # CockroachDB MariaDB Misc # Free IPv6 - TunnelBroker Syslog - Elastic Automation # Web App Automation - Puppeteer Security # Information Gathering # Shodan Snopes Have I been Pwned Learning Material # In this section, I will provide links for free, and paid learning options.\nThe option is something I have used to learn different skills.\nHacking # Beginner - OverTheWire Beginner - XSS Web Mix - TryHackMe Mix - HackTheBox Eget Lab - VulnHub Homemade CTF Pentesting Help # Server: Shodan Server: Onyphe Server: Censys Server: Ivre OSINT: intelx.io Attack Surface: App.Netlas Attack Surface: FullHunt Attack Surface: BinaryEdge Dorks: Google WiFi Networks Codes Search: Grep Codes Search: Searchcode Codes Search: PublicWWW Threat Intelligence Threat Intelligence Threat Intelligence Threat Intelligence Threat Intelligence Threat Intelligence Threat Intelligence Threat Intelligence Email Addresses: Hunter Certificate Search: CRT Vulnerabilities: Vulners ","date":"29 July 2022","externalUrl":null,"permalink":"/posts/04-misc/it_links/good-links/","section":"IT Projects and Resources","summary":"Links # On this post I will provide you with different links, good for graphical arts and IT.","title":"Good Links","type":"posts"},{"content":" Upstream Projects # This section holds information regarding redhat upstream projects.\nUpstream projects are the opensource version of Redhat products.\nThe upstream project is given without any support, and are not suitable for production use.\nRedhat: OpenShift # Redhat Openshift upstram Project OKD Redhat: Ansible Automation Platform # Redhat AAP Upstream project AWX Redhat: Identity Management (IDM) # Redhat Identity Manager\u0026rsquo;s (IDM) upstream project FreeIPA Though having a redhat licens gives you the correct licens to use IDM Redhat: Virtualization # Redhat virtualization upstream project oVirt Linux Distributions # Redhat Family AlmaLinux RockyOS CentOS Debian Family Debian ","date":"2 August 2022","externalUrl":null,"permalink":"/posts/04-misc/upstream_projects_links/upstream-projects/","section":"IT Projects and Resources","summary":"Upstream Projects # This section holds information regarding redhat upstream projects.","title":"Upstream Projects","type":"posts"},{"content":" Different codes and helpers # This includes code for e.g dns, colours, snmp and more.\nDNS Records # Commonly used DNS Records # Type Description A The record that holds the IP address of a domain. AAAA The record that contains the IPv6 address for a domain (as opposed to A records, which list the IPv4 address). CNAME Forwards one domain or subdomain to another domain, does NOT provide an IP address. MX Directs mail to an email server. TXT Lets an admin store text notes in the record. These records are often used for email security. NS Stores the name server for a DNS entry. SOA Stores admin information about a domain. SRV Specifies a port for specific services. PTR Provides a domain name in reverse-lookups. Less commonly used DNS Records # Type Description APL The ‘address prefix list’ is an experiment record that specifies lists of address ranges. AFSDB This record is used for clients of the Andrew File System (AFS) developed by Carnegie Melon. The AFSDB record functions to find other AFS cells. CAA This is the ‘certification authority authorization’ record, it allows domain owners state which certificate authorities can issue certificates for that domain. If no CAA record exists, then anyone can issue a certificate for the domain. These records are also inherited by subdomains. DNSKEY The ‘DNS Key Record’ contains a public key used to verify Domain Name System Security Extension (DNSSEC) signatures CDNSKEY This is a child copy of the DNSKEY record, meant to be transferred to a parent. CERT The ‘certificate record’ stores public key certificates. DCHID The ‘DHCP Identifier’ stores info for the Dynamic Host Configuration Protocol (DHCP), a standardized network protocol used on IP networks. DNAME The ‘delegation name’ record creates a domain alias, just like CNAME, but this alias will redirect all subdomains as well. For instance if the owner of ‘example.com’ bought the domain ‘website.net’ and gave it a DNAME record that points to ‘example.com’, then that pointer would also extend to ‘blog.website.net’ and any other subdomains. HIP This record uses ‘Host identity protocol’, a way to separate the roles of an IP address; this record is used most often in mobile computing. IPSECKEY The ‘IPSEC key’ record works with the Internet Protocol Security (IPSEC), an end-to-end security protocol framework and part of the Internet Protocol Suite (TCP/IP). LOC The ‘location’ record contains geographical information for a domain in the form of longitude and latitude coordinates. NAPTR The ‘name authority pointer’ record can be combined with an SRV record to dynamically create URI’s to point to based on a regular expression. NSEC The ‘next secure record’ is part of DNSSEC, and it’s used to prove that a requested DNS resource record does not exist. RRSIG The ‘resource record signature’ is a record to store digital signatures used to authenticate records in accordance with DNSSEC. RP This is the ‘responsible person’ record and it stores the email address of the person responsible for the domain. SSHFP This record stores the ‘SSH public key fingerprints’; SSH stands for Secure Shell and it’s a cryptographic networking protocol for secure communication over an unsecure network. 256 Color Codes Cheat-Sheet # Colors 0-15 are Xterm system colors.\nXterm Number Xterm Name HEX RGB HSL 0 Black (SYSTEM) #000000 rgb(0,0,0) hsl(0,0%,0%) 1 Maroon (SYSTEM) #800000 rgb(128,0,0) hsl(0,100%,25%) 2 Green (SYSTEM) #008000 rgb(0,128,0) hsl(120,100%,25%) 3 Olive (SYSTEM) #808000 rgb(128,128,0) hsl(60,100%,25%) 4 Navy (SYSTEM) #000080 rgb(0,0,128) hsl(240,100%,25%) 5 Purple (SYSTEM) #800080 rgb(128,0,128) hsl(300,100%,25%) 6 Teal (SYSTEM) #008080 rgb(0,128,128) hsl(180,100%,25%) 7 Silver (SYSTEM) #c0c0c0 rgb(192,192,192) hsl(0,0%,75%) 8 Grey (SYSTEM) #808080 rgb(128,128,128) hsl(0,0%,50%) 9 Red (SYSTEM) #ff0000 rgb(255,0,0) hsl(0,100%,50%) 10 Lime (SYSTEM) #00ff00 rgb(0,255,0) hsl(120,100%,50%) 11 Yellow (SYSTEM) #ffff00 rgb(255,255,0) hsl(60,100%,50%) 12 Blue (SYSTEM) #0000ff rgb(0,0,255) hsl(240,100%,50%) 13 Fuchsia (SYSTEM) #ff00ff rgb(255,0,255) hsl(300,100%,50%) 14 Aqua (SYSTEM) #00ffff rgb(0,255,255) hsl(180,100%,50%) 15 White (SYSTEM) #ffffff rgb(255,255,255) hsl(0,0%,100%) 16 Grey0 #000000 rgb(0,0,0) hsl(0,0%,0%) 17 NavyBlue #00005f rgb(0,0,95) hsl(240,100%,18%) 18 DarkBlue #000087 rgb(0,0,135) hsl(240,100%,26%) 19 Blue3 #0000af rgb(0,0,175) hsl(240,100%,34%) 20 Blue3 #0000d7 rgb(0,0,215) hsl(240,100%,42%) 21 Blue1 #0000ff rgb(0,0,255) hsl(240,100%,50%) 22 DarkGreen #005f00 rgb(0,95,0) hsl(120,100%,18%) 23 DeepSkyBlue4 #005f5f rgb(0,95,95) hsl(180,100%,18%) 24 DeepSkyBlue4 #005f87 rgb(0,95,135) hsl(97,100%,26%) 25 DeepSkyBlue4 #005faf rgb(0,95,175) hsl(07,100%,34%) 26 DodgerBlue3 #005fd7 rgb(0,95,215) hsl(13,100%,42%) 27 DodgerBlue2 #005fff rgb(0,95,255) hsl(17,100%,50%) 28 Green4 #008700 rgb(0,135,0) hsl(120,100%,26%) 29 SpringGreen4 #00875f rgb(0,135,95) hsl(62,100%,26%) 30 Turquoise4 #008787 rgb(0,135,135) hsl(180,100%,26%) 31 DeepSkyBlue3 #0087af rgb(0,135,175) hsl(93,100%,34%) 32 DeepSkyBlue3 #0087d7 rgb(0,135,215) hsl(02,100%,42%) 33 DodgerBlue1 #0087ff rgb(0,135,255) hsl(08,100%,50%) 34 Green3 #00af00 rgb(0,175,0) hsl(120,100%,34%) 35 SpringGreen3 #00af5f rgb(0,175,95) hsl(52,100%,34%) 36 DarkCyan #00af87 rgb(0,175,135) hsl(66,100%,34%) 37 LightSeaGreen #00afaf rgb(0,175,175) hsl(180,100%,34%) 38 DeepSkyBlue2 #00afd7 rgb(0,175,215) hsl(91,100%,42%) 39 DeepSkyBlue1 #00afff rgb(0,175,255) hsl(98,100%,50%) 40 Green3 #00d700 rgb(0,215,0) hsl(120,100%,42%) 41 SpringGreen3 #00d75f rgb(0,215,95) hsl(46,100%,42%) 42 SpringGreen2 #00d787 rgb(0,215,135) hsl(57,100%,42%) 43 Cyan3 #00d7af rgb(0,215,175) hsl(68,100%,42%) 44 DarkTurquoise #00d7d7 rgb(0,215,215) hsl(180,100%,42%) 45 Turquoise2 #00d7ff rgb(0,215,255) hsl(89,100%,50%) 46 Green1 #00ff00 rgb(0,255,0) hsl(120,100%,50%) 47 SpringGreen2 #00ff5f rgb(0,255,95) hsl(42,100%,50%) 48 SpringGreen1 #00ff87 rgb(0,255,135) hsl(51,100%,50%) 49 MediumSpringGreen #00ffaf rgb(0,255,175) hsl(61,100%,50%) 50 Cyan2 #00ffd7 rgb(0,255,215) hsl(70,100%,50%) 51 Cyan1 #00ffff rgb(0,255,255) hsl(180,100%,50%) 52 DarkRed #5f0000 rgb(95,0,0) hsl(0,100%,18%) 53 DeepPink4 #5f005f rgb(95,0,95) hsl(300,100%,18%) 54 Purple4 #5f0087 rgb(95,0,135) hsl(82,100%,26%) 55 Purple4 #5f00af rgb(95,0,175) hsl(72,100%,34%) 56 Purple3 #5f00d7 rgb(95,0,215) hsl(66,100%,42%) 57 BlueViolet #5f00ff rgb(95,0,255) hsl(62,100%,50%) 58 Orange4 #5f5f00 rgb(95,95,0) hsl(60,100%,18%) 59 Grey37 #5f5f5f rgb(95,95,95) hsl(0,0%,37%) 60 MediumPurple4 #5f5f87 rgb(95,95,135) hsl(240,17%,45%) 61 SlateBlue3 #5f5faf rgb(95,95,175) hsl(240,33%,52%) 62 SlateBlue3 #5f5fd7 rgb(95,95,215) hsl(240,60%,60%) 63 RoyalBlue1 #5f5fff rgb(95,95,255) hsl(240,100%,68%) 64 Chartreuse4 #5f8700 rgb(95,135,0) hsl(7,100%,26%) 65 DarkSeaGreen4 #5f875f rgb(95,135,95) hsl(120,17%,45%) 66 PaleTurquoise4 #5f8787 rgb(95,135,135) hsl(180,17%,45%) 67 SteelBlue #5f87af rgb(95,135,175) hsl(210,33%,52%) 68 SteelBlue3 #5f87d7 rgb(95,135,215) hsl(220,60%,60%) 69 CornflowerBlue #5f87ff rgb(95,135,255) hsl(225,100%,68%) 70 Chartreuse3 #5faf00 rgb(95,175,0) hsl(7,100%,34%) 71 DarkSeaGreen4 #5faf5f rgb(95,175,95) hsl(120,33%,52%) 72 CadetBlue #5faf87 rgb(95,175,135) hsl(150,33%,52%) 73 CadetBlue #5fafaf rgb(95,175,175) hsl(180,33%,52%) 74 SkyBlue3 #5fafd7 rgb(95,175,215) hsl(200,60%,60%) 75 SteelBlue1 #5fafff rgb(95,175,255) hsl(210,100%,68%) 76 Chartreuse3 #5fd700 rgb(95,215,0) hsl(3,100%,42%) 77 PaleGreen3 #5fd75f rgb(95,215,95) hsl(120,60%,60%) 78 SeaGreen3 #5fd787 rgb(95,215,135) hsl(140,60%,60%) 79 Aquamarine3 #5fd7af rgb(95,215,175) hsl(160,60%,60%) 80 MediumTurquoise #5fd7d7 rgb(95,215,215) hsl(180,60%,60%) 81 SteelBlue1 #5fd7ff rgb(95,215,255) hsl(195,100%,68%) 82 Chartreuse2 #5fff00 rgb(95,255,0) hsl(7,100%,50%) 83 SeaGreen2 #5fff5f rgb(95,255,95) hsl(120,100%,68%) 84 SeaGreen1 #5fff87 rgb(95,255,135) hsl(135,100%,68%) 85 SeaGreen1 #5fffaf rgb(95,255,175) hsl(150,100%,68%) 86 Aquamarine1 #5fffd7 rgb(95,255,215) hsl(165,100%,68%) 87 DarkSlateGray2 #5fffff rgb(95,255,255) hsl(180,100%,68%) 88 DarkRed #870000 rgb(135,0,0) hsl(0,100%,26%) 89 DeepPink4 #87005f rgb(135,0,95) hsl(17,100%,26%) 90 DarkMagenta #870087 rgb(135,0,135) hsl(300,100%,26%) 91 DarkMagenta #8700af rgb(135,0,175) hsl(86,100%,34%) 92 DarkViolet #8700d7 rgb(135,0,215) hsl(77,100%,42%) 93 Purple #8700ff rgb(135,0,255) hsl(71,100%,50%) 94 Orange4 #875f00 rgb(135,95,0) hsl(2,100%,26%) 95 LightPink4 #875f5f rgb(135,95,95) hsl(0,17%,45%) 96 Plum4 #875f87 rgb(135,95,135) hsl(300,17%,45%) 97 MediumPurple3 #875faf rgb(135,95,175) hsl(270,33%,52%) 98 MediumPurple3 #875fd7 rgb(135,95,215) hsl(260,60%,60%) 99 SlateBlue1 #875fff rgb(135,95,255) hsl(255,100%,68%) 100 Yellow4 #878700 rgb(135,135,0) hsl(60,100%,26%) 101 Wheat4 #87875f rgb(135,135,95) hsl(60,17%,45%) 102 Grey53 #878787 rgb(135,135,135) hsl(0,0%,52%) 103 LightSlateGrey #8787af rgb(135,135,175) hsl(240,20%,60%) 104 MediumPurple #8787d7 rgb(135,135,215) hsl(240,50%,68%) 105 LightSlateBlue #8787ff rgb(135,135,255) hsl(240,100%,76%) 106 Yellow4 #87af00 rgb(135,175,0) hsl(3,100%,34%) 107 DarkOliveGreen3 #87af5f rgb(135,175,95) hsl(90,33%,52%) 108 DarkSeaGreen #87af87 rgb(135,175,135) hsl(120,20%,60%) 109 LightSkyBlue3 #87afaf rgb(135,175,175) hsl(180,20%,60%) 110 LightSkyBlue3 #87afd7 rgb(135,175,215) hsl(210,50%,68%) 111 SkyBlue2 #87afff rgb(135,175,255) hsl(220,100%,76%) 112 Chartreuse2 #87d700 rgb(135,215,0) hsl(2,100%,42%) 113 DarkOliveGreen3 #87d75f rgb(135,215,95) hsl(100,60%,60%) 114 PaleGreen3 #87d787 rgb(135,215,135) hsl(120,50%,68%) 115 DarkSeaGreen3 #87d7af rgb(135,215,175) hsl(150,50%,68%) 116 DarkSlateGray3 #87d7d7 rgb(135,215,215) hsl(180,50%,68%) 117 SkyBlue1 #87d7ff rgb(135,215,255) hsl(200,100%,76%) 118 Chartreuse1 #87ff00 rgb(135,255,0) hsl(8,100%,50%) 119 LightGreen #87ff5f rgb(135,255,95) hsl(105,100%,68%) 120 LightGreen #87ff87 rgb(135,255,135) hsl(120,100%,76%) 121 PaleGreen1 #87ffaf rgb(135,255,175) hsl(140,100%,76%) 122 Aquamarine1 #87ffd7 rgb(135,255,215) hsl(160,100%,76%) 123 DarkSlateGray1 #87ffff rgb(135,255,255) hsl(180,100%,76%) 124 Red3 #af0000 rgb(175,0,0) hsl(0,100%,34%) 125 DeepPink4 #af005f rgb(175,0,95) hsl(27,100%,34%) 126 MediumVioletRed #af0087 rgb(175,0,135) hsl(13,100%,34%) 127 Magenta3 #af00af rgb(175,0,175) hsl(300,100%,34%) 128 DarkViolet #af00d7 rgb(175,0,215) hsl(88,100%,42%) 129 Purple #af00ff rgb(175,0,255) hsl(81,100%,50%) 130 DarkOrange3 #af5f00 rgb(175,95,0) hsl(2,100%,34%) 131 IndianRed #af5f5f rgb(175,95,95) hsl(0,33%,52%) 132 HotPink3 #af5f87 rgb(175,95,135) hsl(330,33%,52%) 133 MediumOrchid3 #af5faf rgb(175,95,175) hsl(300,33%,52%) 134 MediumOrchid #af5fd7 rgb(175,95,215) hsl(280,60%,60%) 135 MediumPurple2 #af5fff rgb(175,95,255) hsl(270,100%,68%) 136 DarkGoldenrod #af8700 rgb(175,135,0) hsl(6,100%,34%) 137 LightSalmon3 #af875f rgb(175,135,95) hsl(30,33%,52%) 138 RosyBrown #af8787 rgb(175,135,135) hsl(0,20%,60%) 139 Grey63 #af87af rgb(175,135,175) hsl(300,20%,60%) 140 MediumPurple2 #af87d7 rgb(175,135,215) hsl(270,50%,68%) 141 MediumPurple1 #af87ff rgb(175,135,255) hsl(260,100%,76%) 142 Gold3 #afaf00 rgb(175,175,0) hsl(60,100%,34%) 143 DarkKhaki #afaf5f rgb(175,175,95) hsl(60,33%,52%) 144 NavajoWhite3 #afaf87 rgb(175,175,135) hsl(60,20%,60%) 145 Grey69 #afafaf rgb(175,175,175) hsl(0,0%,68%) 146 LightSteelBlue3 #afafd7 rgb(175,175,215) hsl(240,33%,76%) 147 LightSteelBlue #afafff rgb(175,175,255) hsl(240,100%,84%) 148 Yellow3 #afd700 rgb(175,215,0) hsl(1,100%,42%) 149 DarkOliveGreen3 #afd75f rgb(175,215,95) hsl(80,60%,60%) 150 DarkSeaGreen3 #afd787 rgb(175,215,135) hsl(90,50%,68%) 151 DarkSeaGreen2 #afd7af rgb(175,215,175) hsl(120,33%,76%) 152 LightCyan3 #afd7d7 rgb(175,215,215) hsl(180,33%,76%) 153 LightSkyBlue1 #afd7ff rgb(175,215,255) hsl(210,100%,84%) 154 GreenYellow #afff00 rgb(175,255,0) hsl(8,100%,50%) 155 DarkOliveGreen2 #afff5f rgb(175,255,95) hsl(90,100%,68%) 156 PaleGreen1 #afff87 rgb(175,255,135) hsl(100,100%,76%) 157 DarkSeaGreen2 #afffaf rgb(175,255,175) hsl(120,100%,84%) 158 DarkSeaGreen1 #afffd7 rgb(175,255,215) hsl(150,100%,84%) 159 PaleTurquoise1 #afffff rgb(175,255,255) hsl(180,100%,84%) 160 Red3 #d70000 rgb(215,0,0) hsl(0,100%,42%) 161 DeepPink3 #d7005f rgb(215,0,95) hsl(33,100%,42%) 162 DeepPink3 #d70087 rgb(215,0,135) hsl(22,100%,42%) 163 Magenta3 #d700af rgb(215,0,175) hsl(11,100%,42%) 164 Magenta3 #d700d7 rgb(215,0,215) hsl(300,100%,42%) 165 Magenta2 #d700ff rgb(215,0,255) hsl(90,100%,50%) 166 DarkOrange3 #d75f00 rgb(215,95,0) hsl(6,100%,42%) 167 IndianRed #d75f5f rgb(215,95,95) hsl(0,60%,60%) 168 HotPink3 #d75f87 rgb(215,95,135) hsl(340,60%,60%) 169 HotPink2 #d75faf rgb(215,95,175) hsl(320,60%,60%) 170 Orchid #d75fd7 rgb(215,95,215) hsl(300,60%,60%) 171 MediumOrchid1 #d75fff rgb(215,95,255) hsl(285,100%,68%) 172 Orange3 #d78700 rgb(215,135,0) hsl(7,100%,42%) 173 LightSalmon3 #d7875f rgb(215,135,95) hsl(20,60%,60%) 174 LightPink3 #d78787 rgb(215,135,135) hsl(0,50%,68%) 175 Pink3 #d787af rgb(215,135,175) hsl(330,50%,68%) 176 Plum3 #d787d7 rgb(215,135,215) hsl(300,50%,68%) 177 Violet #d787ff rgb(215,135,255) hsl(280,100%,76%) 178 Gold3 #d7af00 rgb(215,175,0) hsl(8,100%,42%) 179 LightGoldenrod3 #d7af5f rgb(215,175,95) hsl(40,60%,60%) 180 Tan #d7af87 rgb(215,175,135) hsl(30,50%,68%) 181 MistyRose3 #d7afaf rgb(215,175,175) hsl(0,33%,76%) 182 Thistle3 #d7afd7 rgb(215,175,215) hsl(300,33%,76%) 183 Plum2 #d7afff rgb(215,175,255) hsl(270,100%,84%) 184 Yellow3 #d7d700 rgb(215,215,0) hsl(60,100%,42%) 185 Khaki3 #d7d75f rgb(215,215,95) hsl(60,60%,60%) 186 LightGoldenrod2 #d7d787 rgb(215,215,135) hsl(60,50%,68%) 187 LightYellow3 #d7d7af rgb(215,215,175) hsl(60,33%,76%) 188 Grey84 #d7d7d7 rgb(215,215,215) hsl(0,0%,84%) 189 LightSteelBlue1 #d7d7ff rgb(215,215,255) hsl(240,100%,92%) 190 Yellow2 #d7ff00 rgb(215,255,0) hsl(9,100%,50%) 191 DarkOliveGreen1 #d7ff5f rgb(215,255,95) hsl(75,100%,68%) 192 DarkOliveGreen1 #d7ff87 rgb(215,255,135) hsl(80,100%,76%) 193 DarkSeaGreen1 #d7ffaf rgb(215,255,175) hsl(90,100%,84%) 194 Honeydew2 #d7ffd7 rgb(215,255,215) hsl(120,100%,92%) 195 LightCyan1 #d7ffff rgb(215,255,255) hsl(180,100%,92%) 196 Red1 #ff0000 rgb(255,0,0) hsl(0,100%,50%) 197 DeepPink2 #ff005f rgb(255,0,95) hsl(37,100%,50%) 198 DeepPink1 #ff0087 rgb(255,0,135) hsl(28,100%,50%) 199 DeepPink1 #ff00af rgb(255,0,175) hsl(18,100%,50%) 200 Magenta2 #ff00d7 rgb(255,0,215) hsl(09,100%,50%) 201 Magenta1 #ff00ff rgb(255,0,255) hsl(300,100%,50%) 202 OrangeRed1 #ff5f00 rgb(255,95,0) hsl(2,100%,50%) 203 IndianRed1 #ff5f5f rgb(255,95,95) hsl(0,100%,68%) 204 IndianRed1 #ff5f87 rgb(255,95,135) hsl(345,100%,68%) 205 HotPink #ff5faf rgb(255,95,175) hsl(330,100%,68%) 206 HotPink #ff5fd7 rgb(255,95,215) hsl(315,100%,68%) 207 MediumOrchid1 #ff5fff rgb(255,95,255) hsl(300,100%,68%) 208 DarkOrange #ff8700 rgb(255,135,0) hsl(1,100%,50%) 209 Salmon1 #ff875f rgb(255,135,95) hsl(15,100%,68%) 210 LightCoral #ff8787 rgb(255,135,135) hsl(0,100%,76%) 211 PaleVioletRed1 #ff87af rgb(255,135,175) hsl(340,100%,76%) 212 Orchid2 #ff87d7 rgb(255,135,215) hsl(320,100%,76%) 213 Orchid1 #ff87ff rgb(255,135,255) hsl(300,100%,76%) 214 Orange1 #ffaf00 rgb(255,175,0) hsl(1,100%,50%) 215 SandyBrown #ffaf5f rgb(255,175,95) hsl(30,100%,68%) 216 LightSalmon1 #ffaf87 rgb(255,175,135) hsl(20,100%,76%) 217 LightPink1 #ffafaf rgb(255,175,175) hsl(0,100%,84%) 218 Pink1 #ffafd7 rgb(255,175,215) hsl(330,100%,84%) 219 Plum1 #ffafff rgb(255,175,255) hsl(300,100%,84%) 220 Gold1 #ffd700 rgb(255,215,0) hsl(0,100%,50%) 221 LightGoldenrod2 #ffd75f rgb(255,215,95) hsl(45,100%,68%) 222 LightGoldenrod2 #ffd787 rgb(255,215,135) hsl(40,100%,76%) 223 NavajoWhite1 #ffd7af rgb(255,215,175) hsl(30,100%,84%) 224 MistyRose1 #ffd7d7 rgb(255,215,215) hsl(0,100%,92%) 225 Thistle1 #ffd7ff rgb(255,215,255) hsl(300,100%,92%) 226 Yellow1 #ffff00 rgb(255,255,0) hsl(60,100%,50%) 227 LightGoldenrod1 #ffff5f rgb(255,255,95) hsl(60,100%,68%) 228 Khaki1 #ffff87 rgb(255,255,135) hsl(60,100%,76%) 229 Wheat1 #ffffaf rgb(255,255,175) hsl(60,100%,84%) 230 Cornsilk1 #ffffd7 rgb(255,255,215) hsl(60,100%,92%) 231 Grey100 #ffffff rgb(255,255,255) hsl(0,0%,100%) 232 Grey3 #080808 rgb(8,8,8) hsl(0,0%,3%) 233 Grey7 #121212 rgb(18,18,18) hsl(0,0%,7%) 234 Grey11 #1c1c1c rgb(28,28,28) hsl(0,0%,10%) 235 Grey15 #262626 rgb(38,38,38) hsl(0,0%,14%) 236 Grey19 #303030 rgb(48,48,48) hsl(0,0%,18%) 237 Grey23 #3a3a3a rgb(58,58,58) hsl(0,0%,22%) 238 Grey27 #444444 rgb(68,68,68) hsl(0,0%,26%) 239 Grey30 #4e4e4e rgb(78,78,78) hsl(0,0%,30%) 240 Grey35 #585858 rgb(88,88,88) hsl(0,0%,34%) 241 Grey39 #626262 rgb(98,98,98) hsl(0,0%,37%) 242 Grey42 #6c6c6c rgb(108,108,108) hsl(0,0%,40%) 243 Grey46 #767676 rgb(118,118,118) hsl(0,0%,46%) 244 Grey50 #808080 rgb(128,128,128) hsl(0,0%,50%) 245 Grey54 #8a8a8a rgb(138,138,138) hsl(0,0%,54%) 246 Grey58 #949494 rgb(148,148,148) hsl(0,0%,58%) 247 Grey62 #9e9e9e rgb(158,158,158) hsl(0,0%,61%) 248 Grey66 #a8a8a8 rgb(168,168,168) hsl(0,0%,65%) 249 Grey70 #b2b2b2 rgb(178,178,178) hsl(0,0%,69%) 250 Grey74 #bcbcbc rgb(188,188,188) hsl(0,0%,73%) 251 Grey78 #c6c6c6 rgb(198,198,198) hsl(0,0%,77%) 252 Grey82 #d0d0d0 rgb(208,208,208) hsl(0,0%,81%) 253 Grey85 #dadada rgb(218,218,218) hsl(0,0%,85%) 254 Grey89 #e4e4e4 rgb(228,228,228) hsl(0,0%,89%) 255 Grey93 #eeeeee rgb(238,238,238) hsl(0,0%,93%) SMTP STUFF # SMTP Response Codes Cheat-Sheet # Status Code Description 211 System status or system help response 214 Help message 220 Service ready 221 Service closing transmission channel 235 Authentication successful 250 Requested mail action completed 251 User not local; will forward 252 Cannot verify the user; will attempt delivery 354 Start mail input; end with \u0026lt;CRLF\u0026gt;.\u0026lt;CRLF\u0026gt; 421 Service not available, closing transmission channel 450 Requested action not taken - mailbox unavailable 451 Requested action aborted: local error in processing 452 Requested action not taken - insufficient system storage 500 Syntax error, command unrecognized 501 Syntax error in parameters or arguments 502 Command not implemented 503 Bad sequence of commands 504 Command parameter not implemented 550 Requested action not taken - mailbox unavailable 551 User not local; please try \u0026lt;forward-path\u0026gt; 552 Requested mail action aborted - exceeded storage allocation 553 Requested action not taken - mailbox name not allowed 554 Transaction failed EHLO Response Codes Cheat-Sheet # Please note that the presence and specific EHLO response codes will depend on the SMTP server software, its version, and its configuration. The above table includes some commonly encountered EHLO response codes, but it may not cover every possible code or extension.\nEHLO Response Code Description 250 Requested mail action okay, completed 250-PIPELINING Server supports command pipelining 250-SIZE \u0026lt;value\u0026gt; Server specifies maximum message size 250-ETRN Server supports the ETRN extension 250-ENHANCEDSTATUSCODES Server uses enhanced status codes 250-8BITMIME Server supports the 8BITMIME extension 250-DSN Server supports delivery status notifications (DSN) 250-STARTTLS Server supports TLS encryption 250-AUTH \u0026lt;authentication_types\u0026gt; Server specifies supported authentication types 250-DELIVERBY Server supports the DELIVERBY extension 250-RSET Server supports the RSET command 250-HELP Server provides help information 250-BINARYMIME Server supports binary MIME (Multipurpose Internet Mail Extensions) 250-CHUNKING Server supports chunking for message transmission 250-EXPN Server supports the EXPN command 250-VRFY Server supports the VRFY command 250-X-EXPS \u0026lt;extension\u0026gt; Server supports an additional extension 250 X-LINK2STATE Server provides link-related state information HTTP Status Codes Cheat-Sheet # Categories # Code Description 1XX Informational Requests 2XX Successful Requests 3XX Redirects 4XX Client Errors 5XX Server Errors Complete List - HTTP # Code Name Description 100 Continue Everything so far is OK and that the client should continue with the request or ignore it if it is already finished. 101 Switching Protocols The client has asked the server to change protocols and the server has agreed to do so. 102 Processing The server has received and is processing the request, but that it does not have a final response yet. 103 Early Hints Used to return some response headers before final HTTP message. 200 OK Successful request. 201 Created The server acknowledged the created resource. 202 Accepted The client\u0026rsquo;s request has been received but the server is still processing it. 203 Non-Authoritative Information The response that the server sent to the client is not the same as it was when the server sent it. 204 No Content There is no content to send for this request 205 Reset Content Tells the user agent to reset the document which sent this request. 206 Partial Content This response code is used when the range-header is sent from the client to request only part of a resource. 207 Multi-Status Conveys information about multiple resources, for situations where multiple status codes might be appropriate. 208 Already Reported The members of a DAV binding have already been enumerated in a preceding part of the multi-status response. 226 IM Used IM is a specific extension of the HTTP protocol. The extension allows a HTTP server to send diffs (changes) of resources to clients. 300 Multiple Choices The request has more than one possible response. The user agent should choose one. 301 Moved Permanently The URL of the requested resource has been changed permanently. The new URL is given in the response. 302 Found This response code means that the URI of requested resource has been changed temporarily 303 See Other The server sent this response to direct the client to get the requested resource at another URI with a GET request. 304 Not Modified It tells the client that the response has not been modified, so the client can continue to use the same cached version of the response. 305 Use Proxy Defined in a previous version of the HTTP specification to indicate that a requested response must be accessed by a proxy. (discontinued) 307 Temporary Redirect The server sends this response to direct the client to get the requested resource at another URI with same method that was used in the prior request. 308 Permanent Redirect This means that the resource is now permanently located at another URI, specified by the Location: HTTP Response header. 400 Bad Request The server could not understand the request 401 Unauthorized The client didn\u0026rsquo;t authenticate himself. 402 Payment Required This response code is reserved for future use. The initial aim for creating this code was using it for digital payment systems, however this status code is used very rarely and no standard convention exists. 403 Forbidden The client does not have access rights to the content 404 Not Found The server can not find the requested resource 405 Method Not Allowed The request method is known by the server but is not supported by the target resource 406 Not Acceptable The reponse doens\u0026rsquo;t conforms to the creteria given by the client 407 Proxy Authentication Required This is similar to 401 Unauthorized but authentication is needed to be done by a proxy. 408 Request Timeout This response is sent on an idle connection by some servers, even without any previous request by the client. 409 Conflict This response is sent when a request conflicts with the current state of the server. 410 Gone This response is sent when the requested content has been permanently deleted from server, with no forwarding address. 411 Length Required Server rejected the request because the Content-Length header field is not defined and the server requires it. 412 Precondition Failed Access to the target resource has been denied. 413 Payload Too Large Request entity is larger than limits defined by server. 414 Request-URI Too Long The URI requested by the client is longer than the server is willing to interpret. 415 Unsupported Media Type The media format is not supported by the server. 416 Requested Range Not Satisfiable The range specified by the Range header field in the request cannot be fulfilled. 417 Expectation Failed the expectation indicated by the Expect request header field cannot be met by the server. 418 I\u0026rsquo;m a teapot The server refuses the attempt to brew coffee with a teapot. 421 Misdirected Request The request was directed at a server that is not able to produce a response. 422 Unprocessable Entity The request was well-formed but was unable to be followed due to semantic errors. 423 Locked The resource that is being accessed is locked. 424 Failed Dependency The request failed due to failure of a previous request. 426 Upgrade Required The server refuses to perform the request using the current protocol but might be willing to do so after the client upgrades to a different protocol. 428 Precondition Required his response is intended to prevent the \u0026rsquo;lost update\u0026rsquo; problem, where a client GETs a resource\u0026rsquo;s state, modifies it and PUTs it back to the server, when meanwhile a third party has modified the state on the server, leading to a conflict. 429 Too Many Requests The user has sent too many requests in a given amount of time 431 Request Header Fields Too Large The server is can\u0026rsquo;t process the request because its header fields are too large. 444 Connection Closed Without Response The connection opened, but no data was written. 451 Unavailable For Legal Reasons The user agent requested a resource that cannot legally be provided (such as a web page censored by a government) 499 Client Closed Request The client closed the connection, despite the server was processing the request already. 500 Internal Server Error The server has encountered a situation it does not know how to handle. 501 Not Implemented The request method is not supported by the server and cannot be handled. 502 Bad Gateway This error response means that the server, while working as a gateway to get a response needed to handle the request, got an invalid response. 503 Service Unavailable The server is not ready to handle the request. 504 Gateway Timeout This error response is given when the server is acting as a gateway and cannot get a response in time. 505 HTTP Version Not Supported The HTTP version used in the request is not supported by the server. 506 Variant Also Negotiates the chosen variant resource is configured to engage in transparent content negotiation itself, and is therefore not a proper end point in the negotiation process. 507 Insufficient Storage The method could not be performed on the resource because the server is unable to store the representation needed to successfully complete the request. 508 Loop Detected The server detected an infinite loop while processing the request. 510 Not Extended Further extensions to the request are required for the server to fulfill it. 511 Network Authentication Required Indicates that the client needs to authenticate to gain network access. 599 Network Connect Timeout Error The connection timed out due to a overloaded server, a hardware error or a infrastructure error. ","date":"19 May 2024","externalUrl":null,"permalink":"/posts/04-misc/good_to_know_cheat_sheet/cheat-sheet-codes/","section":"IT Projects and Resources","summary":"Different codes and helpers # This includes code for e.","title":"Cheat Sheet for Different Color Codes, Status Codes, and More","type":"posts"},{"content":" Convert PDF to HTML # This post will explain how you can get a free website using GitHub, and github pages. This was generated because i needed a way to take a portfolio pdf file and turn it into a website. The following takes a pdf and just convert it to a index.html file that points to images taken of the pdf. SO it isn\u0026rsquo;t really converting to html, but more converting pages to images and then refering those with a html index.html file.\nPrerequisites # You need to have a GitHub account. Install the required dependencies on your machine. How to Install Dependencies # Install the required Python packages:\npip install pdf2image pillow Install poppler-utils (required by pdf2image):\nsudo apt-get install poppler-utils Step 1: Prepare Your PDF File # Place your PDF file in the same directory as the script. If your PDF is not named portfolio.pdf, either rename it to portfolio.pdf or edit the script to use your PDF file\u0026rsquo;s name. Step 2: Run the Script # To generate the HTML files from your PDF, use the following script named convert_pdf.py:\n# How to use # 1. Install the required dependencies: # - Install Python packages: # pip install pdf2image pillow # - Install poppler-utils (required by pdf2image): # sudo apt-get install poppler-utils # 2. Run the script: # - To use default settings: # python3 convert_pdf.py # - To specify a PDF file and output folder: # python3 convert_pdf.py path/to/your_pdf_file.pdf path/to/output_folder from pdf2image import convert_from_path import os import sys # Default PDF file and output folder pdf_file = \u0026#34;portfolio.pdf\u0026#34; # Default PDF file name output_folder = \u0026#34;webpage\u0026#34; # Default folder where the HTML and images will be saved # Check for command-line arguments to override defaults if len(sys.argv) \u0026gt; 1: pdf_file = sys.argv[1] # First command-line argument is the PDF file print(f\u0026#34;Using provided PDF file: {pdf_file}\u0026#34;) else: print(f\u0026#34;No PDF file provided. Using default: {pdf_file}\u0026#34;) if len(sys.argv) \u0026gt; 2: output_folder = sys.argv[2] # Second command-line argument is the output folder print(f\u0026#34;Using provided output folder: {output_folder}\u0026#34;) else: print(f\u0026#34;No output folder provided. Using default: {output_folder}\u0026#34;) # Subfolder to store the images src_folder = os.path.join(output_folder, \u0026#34;assets\u0026#34;) # Start the conversion process print(\u0026#34;Starting PDF to HTML conversion...\u0026#34;) print(f\u0026#34;PDF file to convert: {pdf_file}\u0026#34;) print(f\u0026#34;Output folder: {output_folder}\u0026#34;) # Create the output and src folders if they don\u0026#39;t exist print(\u0026#34;Creating necessary directories...\u0026#34;) if not os.path.exists(output_folder): os.makedirs(output_folder) # Create the output directory print(f\u0026#34;Created directory: {output_folder}\u0026#34;) if not os.path.exists(src_folder): os.makedirs(src_folder) # Create the subdirectory for images print(f\u0026#34;Created directory: {src_folder}\u0026#34;) # Convert PDF to images print(\u0026#34;Converting PDF to images...\u0026#34;) try: # Convert each page of the PDF into an image at 300 DPI resolution pages = convert_from_path(pdf_file, 300) print(f\u0026#34;Successfully converted {len(pages)} pages from PDF to images.\u0026#34;) except Exception as e: # If there is an error during conversion, print the error and exit print(f\u0026#34;Error during PDF to image conversion: {e}\u0026#34;) exit() # Initialize a list to store the paths of the saved images image_files = [] for i, page in enumerate(pages): # Define the filename for each image (page_1.jpg, page_2.jpg, etc.) image_filename = os.path.join(src_folder, f\u0026#39;page_{i+1}.jpg\u0026#39;) try: # Save each page as a JPEG image in the src folder page.save(image_filename, \u0026#39;JPEG\u0026#39;) image_files.append(image_filename) print(f\u0026#34;Saved image: {image_filename}\u0026#34;) except Exception as e: # If there is an error saving an image, print the error print(f\u0026#34;Error saving image {image_filename}: {e}\u0026#34;) # Begin generating the HTML file print(\u0026#34;Generating HTML file...\u0026#34;) html_content = \u0026#34;\u0026#34;\u0026#34; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;style\u0026gt; body { margin: 0; padding: 0; background-color: #f0f0f0; /* Set a light background color */ } img { display: block; margin: 0 auto; /* Center images horizontally */ } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026#34;\u0026#34;\u0026#34; # Add each image to the HTML content print(\u0026#34;Adding images to the HTML content...\u0026#34;) for i in range(len(image_files)): image_file = os.path.join(\u0026#34;src\u0026#34;, f\u0026#39;page_{i+1}.jpg\u0026#39;) # Add a div for each image with 100% width and a max-width of 1200px html_content += f\u0026#39;\u0026lt;div\u0026gt;\u0026lt;img src=\u0026#34;{image_file}\u0026#34; style=\u0026#34;width:100%; max-width:1200px;\u0026#34;/\u0026gt;\u0026lt;/div\u0026gt;\\n\u0026#39; print(f\u0026#34;Added image {image_file} to HTML content.\u0026#34;) html_content += \u0026#34;\u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt;\u0026#34; # Define the filename for the index HTML file html_filename = os.path.join(output_folder, \u0026#34;index.html\u0026#34;) print(f\u0026#34;Saving HTML file to: {html_filename}\u0026#34;) try: # Write the generated HTML content to the output file with open(html_filename, \u0026#34;w\u0026#34;) as f: f.write(html_content) print(f\u0026#34;HTML file created successfully: {html_filename}\u0026#34;) except Exception as e: # If there is an error writing the HTML file, print the error print(f\u0026#34;Error writing HTML file: {e}\u0026#34;) To run the script:\nUsing default settings (PDF file named portfolio.pdf and output folder webpage):\npython3 convert_pdf.py To specify a custom PDF file and output folder:\npython3 convert_pdf.py path/to/your_pdf_file.pdf path/to/output_folder Step 3: Upload to GitHub Pages # Create a Repository: On GitHub, create a new repository named \u0026lt;YOUR USERNAME\u0026gt;.github.io. Upload Files: Upload the contents of your output folder (including index.html and the assets folder) to the repository. Publish: Once uploaded, your site will be live at https://\u0026lt;YOUR USERNAME\u0026gt;.github.io. Step 4: Visit Your Website # After uploading the files, visit your new website by navigating to https://\u0026lt;YOUR USERNAME\u0026gt;.github.io in your web browser.\n","date":"13 August 2024","externalUrl":null,"permalink":"/posts/04-misc/generate_portfolio_website/pdf_to_html/","section":"IT Projects and Resources","summary":"Convert PDF to HTML # This post will explain how you can get a free website using GitHub, and github pages.","title":"Generating free portfolio website from PDF file.","type":"posts"},{"content":"","date":"13 August 2024","externalUrl":null,"permalink":"/tags/html/","section":"Tags","summary":"","title":"Html","type":"tags"},{"content":"","date":"13 August 2024","externalUrl":null,"permalink":"/posts/04-misc/","section":"IT Projects and Resources","summary":"","title":"misc","type":"posts"},{"content":"","date":"13 August 2024","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"13 August 2024","externalUrl":null,"permalink":"/tags/website/","section":"Tags","summary":"","title":"Website","type":"tags"},{"content":"","date":"27 July 2024","externalUrl":null,"permalink":"/tags/guide/","section":"Tags","summary":"","title":"Guide","type":"tags"},{"content":"","date":"27 July 2024","externalUrl":null,"permalink":"/tags/windows/","section":"Tags","summary":"","title":"Windows","type":"tags"},{"content":"","date":"27 July 2024","externalUrl":null,"permalink":"/posts/03-windows/","section":"IT Projects and Resources","summary":"","title":"Windows","type":"posts"},{"content":" ","date":"23 June 2024","externalUrl":null,"permalink":"/","section":"IT Projects and Resources","summary":" ","title":"IT Projects and Resources","type":"page"},{"content":"Welcome to my collection of IT projects and resources. Below, you\u0026rsquo;ll find a comprehensive list of topics and guides that cover various aspects of IT, ranging from scripting languages to configuration management and beyond.\nBlog Posts # ansible # Ansible Jinja Helpers Ansible Best Practices and help linux # OpenSource AI Server Certificate Creation guide Linux dot config Linux Cheat Sheets commands Mastering Load Balancing with Nginx and HAProxy windows # Windows Subsystem for Linux (WSL) misc # Jekyll Setup Cheat Sheet for Different Color Codes, Status Codes, and More Good Links Markdown Help Upstream Projects ","date":"23 June 2024","externalUrl":null,"permalink":"/posts/","section":"IT Projects and Resources","summary":"Welcome to my collection of IT projects and resources.","title":"IT Projects and Resources","type":"posts"},{"content":"","date":"19 June 2024","externalUrl":null,"permalink":"/tags/haproxy/","section":"Tags","summary":"","title":"Haproxy","type":"tags"},{"content":"","date":"19 June 2024","externalUrl":null,"permalink":"/posts/02-linux/","section":"IT Projects and Resources","summary":"","title":"Linux","type":"posts"},{"content":"","date":"19 June 2024","externalUrl":null,"permalink":"/tags/nginx/","section":"Tags","summary":"","title":"Nginx","type":"tags"},{"content":"","date":"19 May 2024","externalUrl":null,"permalink":"/categories/bash/","section":"Categories","summary":"","title":"Bash","type":"categories"},{"content":"","date":"19 May 2024","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","date":"19 May 2024","externalUrl":null,"permalink":"/categories/cheat-sheet/","section":"Categories","summary":"","title":"Cheat-Sheet","type":"categories"},{"content":"","date":"19 May 2024","externalUrl":null,"permalink":"/categories/commands/","section":"Categories","summary":"","title":"Commands","type":"categories"},{"content":"","date":"19 May 2024","externalUrl":null,"permalink":"/tags/dns/","section":"Tags","summary":"","title":"Dns","type":"tags"},{"content":"","date":"19 May 2024","externalUrl":null,"permalink":"/categories/linux/","section":"Categories","summary":"","title":"Linux","type":"categories"},{"content":"","date":"19 May 2024","externalUrl":null,"permalink":"/tags/snmp/","section":"Tags","summary":"","title":"Snmp","type":"tags"},{"content":"","date":"19 May 2024","externalUrl":null,"permalink":"/categories/sql/","section":"Categories","summary":"","title":"Sql","type":"categories"},{"content":"","date":"5 May 2024","externalUrl":null,"permalink":"/tags/ai/","section":"Tags","summary":"","title":"AI","type":"tags"},{"content":"","date":"5 May 2024","externalUrl":null,"permalink":"/categories/guide/","section":"Categories","summary":"","title":"Guide","type":"categories"},{"content":"","date":"5 May 2024","externalUrl":null,"permalink":"/tags/it/","section":"Tags","summary":"","title":"It","type":"tags"},{"content":"","date":"5 May 2024","externalUrl":null,"permalink":"/categories/opensource/","section":"Categories","summary":"","title":"OpenSource","type":"categories"},{"content":" OpenSource AI Server # In this blog post i will be showing you how to setup an AI server that looks a bit like ChatGPT. It uses OpenSource projects like:\nollama Open-webui Diffrent opensource models NOTE: you can also install RHEL 8 on wsl but i will not provide a guide as it is writen here\nNote: Instructlab can be installed for better working with LLM\u0026rsquo;s instructlab: guide I did a install nvidia cuda and then there is the ilab command (read documentation)\nInstallation # I\u0026rsquo;ll install on wsl as this is just my home test server. But this should work on any linux host. First i spin up my wsl instance, and then I do the following.\nInstall ollama # Install ollama curl -fsSL https://ollama.com/install.sh | sh check the script before running! Start the ollama server: sudo systemctl enable ollama sudo systemctl start ollama Open a new connection to the server in seperate window pull a model (check available models here)[https://ollama.com/library]\nollama pull llama3 Install docker and open-webui # If yu want to use open-webui you need docker:\n# Add Docker\u0026#39;s official GPG key: sudo apt-get update -y sudo apt-get install ca-certificates curl -y sudo install -m 0755 -d /etc/apt/keyrings sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc sudo chmod a+r /etc/apt/keyrings/docker.asc # Add the repository to Apt sources: echo \\ \u0026#34;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \\ $(. /etc/os-release \u0026amp;\u0026amp; echo \u0026#34;$VERSION_CODENAME\u0026#34;) stable\u0026#34; | \\ sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null sudo apt-get update -y # Install Docker sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin -y # Add your user to the docker group sudo usermod -a -G docker $USER To run the web ui: docker run -d --network=host -v open-webui:/app/backend/data -e OLLAMA_BASE_URL=http://127.0.0.1:11434 --name ebdruplab_open-webui --restart always ghcr.io/open-webui/open-webui:main\nto expose the webui if you are on wsl use netsh interface portproxy add v4tov4 listenport=80 listenaddress=YOUR_HOST_IP connectport=8080 connectaddress=127.0.0.1\nOpen-webui Model example # Here I will provide you with examples on how to tweak your robot to perform better on diffrent tasks\nAnsible-Helper # Example model for ansible use: Name: Ansible_helper\nDescription: Helps Creating Ansible Code llama3:latest or Codegemma:Latest:\nFROM llama3:latest PARAMETER num_ctx 16384 SYSTEM \u0026#34;\u0026#34;\u0026#34;Ansible-Helper provides direct infomation on Ansible, Bash and python code. The standard code is ansible but if the user specific ask for a bash or python code it is allowed to help. Python is mainly focussed in the cotext of asnible. Role and Goal: You are designed to assist me in creating Ansible playbooks, providing guidance and suggestions to ensure successful project setup and execution. Ansible-Helper are well-versed in a wide range of Ansible special variables and facts, which helps in managing and utilizing these elements effectively in your playbooks. Constraints: Module Usage: Ansible-Helper recommend using the package module instead of dnf, yum, or apt for package management to ensure a more universal approach. Variable Naming: Ansible-Helper use snake-case for all variables. Targeting Hosts: Ansible-Helper suggest using \u0026#39;hosts: example\u0026#39; for simple and clear targeting in playbook examples. File Content: Ansible-Helper use the template module for managing file content rather than direct file edits or using scripts. Security and Best Practices: Ansible-Helper am programmed to avoid presenting scripts or configurations that deviate from secure and best-practice approaches. Please use fully qualified collection names like ansible.builtin.yum instead of just yum. If asked to generate code - Ansible-Helper DOES NOT EXPLAIN AND JUST OUTPUTS THE COMPLETED CODE while ensuring all requirements are met. When providing a name to a task it represente what actually happens in the task, and it does to by setting \u0026#39;\u0026#39; arround no variables are allowed in the -name: \u0026#39;HERE\u0026#39; part. Ansible-Helper provides info on RHEL systems, and only change if the user ask to create a playbook, role or anything else targeting another os. Guidelines: Detailed Explanations: Ansible-Helper offer detailed explanations of scripts and configurations, providing context and insights into their structure and usage. Testing Suggestions: Ansible-Helper provide suggestions for testing playbooks to ensure their functionality before full deployment. Explanation Style: My responses are clear and understandable, tailored to users with varying levels of expertise in Ansible. Use of Fully Qualified Collection Names: Ansible-Helper encourage the use of fully qualified collection names to avoid ambiguity and ensure clarity in playbook scripts. Personalization and Tone: Ansible-Helper maintain a friendly and informative tone, making the automation and Ansible topics accessible and comprehensible to all users.\u0026#34;\u0026#34;\u0026#34; img_for_the_bot:\nInstall guide of instructlab # This is a mini guide that provides a more development approach. I will be showing you how to install instructlab on ubuntu. As the official guide only focus on RHEL. Ilab is used to train models on an easier more non-dev way. Using yaml books.\nsudo apt update sudo apt install g++ gcc make python3-pip python3-dev python3-git mkdir instructlab cd instructlab python3 -m venv --upgrade-deps venv source venv/bin/activate pip cache remove llama_cpp_python # check offical documentation for this command for your specific needs # I\u0026#39;ll need nvidea cuda pip install git+https://github.com/instructlab/instructlab.git@stable --extra-index-url=https://download.pytorch.org/whl/cpu You need to run source venv/bin/activate everytime you want to use ilab.\nalso for bash completion you can put eval \u0026quot;$(_ILAB_COMPLETE=bash_source ilab)\u0026quot; insite your .bash_profile or .bashrc file\nNow you can use the ilab commands.\nConclusion # In this blog post, we explored how to set up an AI server using OpenSource projects like Ollama, Open-webui, and different open-source models. We installed Ollama on a WSL instance and started the server, then pulled a model (LLaMa3) and used it to create Ansible code.\nWe also installed Docker and Open-webui, which allows us to run the web UI and interact with the AI server. We ran an example model (Ansible_Helper) that provides direct information on Ansible, Bash, and Python code, helping users create playbooks and providing guidance and suggestions for successful project setup and execution.\nThe key takeaways from this blog post are:\nInstall Ollama: Use the script provided by Ollama to install the server on your WSL instance. Start Ollama Server: Enable and start the Ollama server using systemd. Pull a Model: Pull a model (e.g., LLaMa3) from the Ollama library to use for creating code. Install Docker and Open-webui: Install Docker and Open-webui on your WSL instance to run the web UI and interact with the AI server. un an Example Model: Run an example model (e.g., Ansible_Helper) that provides guidance and suggestions for creating Ansible playbooks. Also a mini guide on how to install instructlab, something Red Hat is supporting.\nThis setup allows you to create an AI-powered server that can assist in automating tasks, such as creating Ansible code, and provides a foundation for building more advanced AI-powered automation tools.\n","date":"5 May 2024","externalUrl":null,"permalink":"/posts/02-linux/ai-misc/2024-05-05-opensource_ai_server/","section":"IT Projects and Resources","summary":"OpenSource AI Server # In this blog post i will be showing you how to setup an AI server that looks a bit like ChatGPT.","title":"OpenSource AI Server","type":"posts"},{"content":"","date":"28 April 2024","externalUrl":null,"permalink":"/tags/linux/","section":"Tags","summary":"","title":"Linux","type":"tags"},{"content":"","date":"27 April 2024","externalUrl":null,"permalink":"/tags/information/","section":"Tags","summary":"","title":"Information","type":"tags"},{"content":"","date":"15 April 2024","externalUrl":null,"permalink":"/tags/certificates/","section":"Tags","summary":"","title":"Certificates","type":"tags"},{"content":"","date":"15 April 2024","externalUrl":null,"permalink":"/tags/certs/","section":"Tags","summary":"","title":"Certs","type":"tags"},{"content":"","date":"15 April 2024","externalUrl":null,"permalink":"/tags/helpers/","section":"Tags","summary":"","title":"Helpers","type":"tags"},{"content":"","date":"15 April 2024","externalUrl":null,"permalink":"/tags/notes/","section":"Tags","summary":"","title":"Notes","type":"tags"},{"content":"","date":"15 April 2024","externalUrl":null,"permalink":"/tags/scripts/","section":"Tags","summary":"","title":"Scripts","type":"tags"},{"content":"","date":"14 April 2024","externalUrl":null,"permalink":"/tags/ansible/","section":"Tags","summary":"","title":"Ansible","type":"tags"},{"content":"","date":"14 April 2024","externalUrl":null,"permalink":"/posts/01-ansible/","section":"IT Projects and Resources","summary":"","title":"Ansible","type":"posts"},{"content":"","date":"14 April 2024","externalUrl":null,"permalink":"/tags/automation/","section":"Tags","summary":"","title":"Automation","type":"tags"},{"content":"","date":"10 April 2024","externalUrl":null,"permalink":"/tags/jinja2/","section":"Tags","summary":"","title":"Jinja2","type":"tags"},{"content":"","date":"2 August 2022","externalUrl":null,"permalink":"/tags/links/","section":"Tags","summary":"","title":"Links","type":"tags"},{"content":"","date":"2 August 2022","externalUrl":null,"permalink":"/tags/opensource/","section":"Tags","summary":"","title":"Opensource","type":"tags"},{"content":"","date":"2 August 2022","externalUrl":null,"permalink":"/categories/project/","section":"Categories","summary":"","title":"Project","type":"categories"},{"content":"","date":"29 July 2022","externalUrl":null,"permalink":"/categories/links/","section":"Categories","summary":"","title":"Links","type":"categories"},{"content":"","date":"1 January 0001","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","date":"1 January 0001","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"}]